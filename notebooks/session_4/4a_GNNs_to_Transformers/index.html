<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GNNs to Transformers &mdash; Graph Neural Networks and Transformers  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinx_lesson.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinx_rtd_theme_ext_color_contrast.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/overrides.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/minipres.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../../../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script data-domain="enccs.github.io/gnn-transformers" defer="defer" src="https://plausible.io/js/script.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="Quick Reference" href="../../../quick-reference/" />
    <link rel="prev" title="Implementing a Graph Neural Network" href="../../session_3/3a_Graph_Neural_Network_Encoder_solutions/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            Graph Neural Networks and Transformers
              <img src="../../../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Presentations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../presentations/">Presentations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notebooks and colab</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks_and_colab/">Notebooks and Colab</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Session 1</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../session_1/1a_representing_graphs_for_neural_networks_solutions/">Representing graphs for neural networks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Session 1 extra material</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../session_1/1b_vector_sums_vs_concatenation/">Summing or concatenating embeddings?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Session 2</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../session_2/2a_full_training_pipeline/">Datasets, Dataloaders and Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Session 3</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../session_3/3a_Graph_Neural_Network_Encoder_solutions/">Implementing a Graph Neural Network</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Session 4</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">GNNs to Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#code-from-previous-notebooks">Code from previous notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-step">Training step</a></li>
<li class="toctree-l2"><a class="reference internal" href="#from-gnns-to-transformers">From GNNs to Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dynamically-computed-adjacency-matrix">Dynamically computed “adjacency matrix”</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-downside">The downside</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-a-transformer">Implementing a Transformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#adding-the-graph-structure-to-transformers">Adding the graph structure to Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#edge-features-in-the-attention">Edge features in the attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#edge-features-in-the-transformations">Edge features in the transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pairwise-features">Pairwise features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#representing-the-path-information">Representing the path information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slow-training">Slow training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#a-note-on-efficiency">A note on efficiency</a></li>
<li class="toctree-l2"><a class="reference internal" href="#task">Task</a></li>
<li class="toctree-l2"><a class="reference internal" href="#learning-outcomes">Learning outcomes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#important-concepts">Important concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-about-this-multi-head-attention">What about this <em>multi-head</em> attention?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#what-is-multi-head-self-attention">What is multi-head self-attention?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quick-reference/">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide/">Instructor’s guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cluster guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lumi/">Running the material on the LUMI super computer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">Graph Neural Networks and Transformers</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">GNNs to Transformers</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/gnn_transformers/blob/main/content/notebooks/session_4/4a_GNNs_to_Transformers.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="gnns-to-transformers">
<h1>GNNs to Transformers<a class="headerlink" href="#gnns-to-transformers" title="Permalink to this heading"></a></h1>
<p>We’ve previously seen how we can implement <em>graph convolutions</em> using multiplication with the adjacency matrix. In this notebook we will look at how this can be extended to a <em>Transformer</em> by  <em>computing</em> an adjacency matrix.</p>
<p>You can find this notebook on Google Colab <a class="reference external" href="http://colab.research.google.com/github/ENCCS/gnn_transformers_notebooks/blob/main/colab/4a_GNNs_to_Transformers.ipynb">here</a></p>
<section id="code-from-previous-notebooks">
<h2>Code from previous notebooks<a class="headerlink" href="#code-from-previous-notebooks" title="Permalink to this heading"></a></h2>
<p>We will use the same example as in the previous notebooks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Set</span>

<span class="kn">import</span> <span class="nn">rdkit</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem</span> <span class="kn">import</span> <span class="n">MolFromSmiles</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem.Draw</span> <span class="kn">import</span> <span class="n">IPythonConsole</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem</span> <span class="kn">import</span> <span class="n">Draw</span>
<span class="n">IPythonConsole</span><span class="o">.</span><span class="n">ipython_useSVG</span><span class="o">=</span><span class="kc">True</span>  <span class="c1">#&lt; set this to False if you want PNGs instead of SVGs</span>
<span class="n">IPythonConsole</span><span class="o">.</span><span class="n">drawOptions</span><span class="o">.</span><span class="n">addAtomIndices</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># This will help when looking at the Mol graph representation</span>
<span class="n">IPythonConsole</span><span class="o">.</span><span class="n">molSize</span> <span class="o">=</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">600</span>

<span class="c1"># We supress RDKit errors for this notebook</span>
<span class="kn">from</span> <span class="nn">rdkit</span> <span class="kn">import</span> <span class="n">RDLogger</span>
<span class="n">RDLogger</span><span class="o">.</span><span class="n">DisableLog</span><span class="p">(</span><span class="s1">&#39;rdApp.*&#39;</span><span class="p">)</span>  


<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">float_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>  <span class="c1"># We&#39;re hardcoding types in the tensors further down</span>
<span class="n">categorical_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span>
<span class="n">mask_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>  <span class="c1"># We&#39;re going to be multiplying our internal calculations with a mask using this type</span>
<span class="n">labels_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span> <span class="c1"># We&#39;re going to use BCEWithLogitsLoss, which expects the labels to be of the same type as the predictions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ContinuousVariable</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

  <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;&lt;ContinuousVariable: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&gt;&#39;</span>

  <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">name</span>

  <span class="k">def</span> <span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">CategoricalVariable</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">add_null_value</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">has_null_value</span> <span class="o">=</span> <span class="n">add_null_value</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_null_value</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">null_value</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">values</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">value_to_idx_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">values</span><span class="p">)}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">inv_value_to_idx_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_to_idx_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_null_value</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">null_value_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_to_idx_mapping</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">null_value</span><span class="p">]</span>
  
  <span class="k">def</span> <span class="nf">get_null_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_null_value</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">null_value_idx</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Categorical variable </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> has no null value&quot;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">value_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_to_idx_mapping</span><span class="p">[</span><span class="n">value</span><span class="p">]</span>
  
  <span class="k">def</span> <span class="nf">idx_to_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_value_to_idx_mapping</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
  
  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;&lt;CategoricalVariable: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&gt;&#39;</span>

  <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">values</span>

  <span class="k">def</span> <span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">hash</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ATOM_SYMBOLS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="s1">&#39;He&#39;</span><span class="p">,</span> <span class="s1">&#39;Li&#39;</span><span class="p">,</span> <span class="s1">&#39;Be&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;O&#39;</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">,</span> <span class="s1">&#39;Ne&#39;</span><span class="p">,</span> <span class="s1">&#39;Na&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Mg&#39;</span><span class="p">,</span> <span class="s1">&#39;Al&#39;</span><span class="p">,</span> <span class="s1">&#39;Si&#39;</span><span class="p">,</span> <span class="s1">&#39;P&#39;</span><span class="p">,</span> <span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;Cl&#39;</span><span class="p">,</span> <span class="s1">&#39;Ar&#39;</span><span class="p">,</span> <span class="s1">&#39;K&#39;</span><span class="p">,</span> <span class="s1">&#39;Ca&#39;</span><span class="p">,</span> <span class="s1">&#39;Sc&#39;</span><span class="p">,</span> <span class="s1">&#39;Ti&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;V&#39;</span><span class="p">,</span> <span class="s1">&#39;Cr&#39;</span><span class="p">,</span> <span class="s1">&#39;Mn&#39;</span><span class="p">,</span> <span class="s1">&#39;Fe&#39;</span><span class="p">,</span> <span class="s1">&#39;Co&#39;</span><span class="p">,</span> <span class="s1">&#39;Ni&#39;</span><span class="p">,</span> <span class="s1">&#39;Cu&#39;</span><span class="p">,</span> <span class="s1">&#39;Zn&#39;</span><span class="p">,</span> <span class="s1">&#39;Ga&#39;</span><span class="p">,</span> <span class="s1">&#39;Ge&#39;</span><span class="p">,</span> <span class="s1">&#39;As&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Se&#39;</span><span class="p">,</span> <span class="s1">&#39;Br&#39;</span><span class="p">,</span> <span class="s1">&#39;Kr&#39;</span><span class="p">,</span> <span class="s1">&#39;Rb&#39;</span><span class="p">,</span> <span class="s1">&#39;Sr&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;Zr&#39;</span><span class="p">,</span> <span class="s1">&#39;Nb&#39;</span><span class="p">,</span> <span class="s1">&#39;Mo&#39;</span><span class="p">,</span> <span class="s1">&#39;Tc&#39;</span><span class="p">,</span> <span class="s1">&#39;Ru&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Rh&#39;</span><span class="p">,</span> <span class="s1">&#39;Pd&#39;</span><span class="p">,</span> <span class="s1">&#39;Ag&#39;</span><span class="p">,</span> <span class="s1">&#39;Cd&#39;</span><span class="p">,</span> <span class="s1">&#39;In&#39;</span><span class="p">,</span> <span class="s1">&#39;Sn&#39;</span><span class="p">,</span> <span class="s1">&#39;Sb&#39;</span><span class="p">,</span> <span class="s1">&#39;Te&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;Xe&#39;</span><span class="p">,</span> <span class="s1">&#39;Cs&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Ba&#39;</span><span class="p">,</span> <span class="s1">&#39;Hf&#39;</span><span class="p">,</span> <span class="s1">&#39;Ta&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;Re&#39;</span><span class="p">,</span> <span class="s1">&#39;Os&#39;</span><span class="p">,</span> <span class="s1">&#39;Ir&#39;</span><span class="p">,</span> <span class="s1">&#39;Pt&#39;</span><span class="p">,</span> <span class="s1">&#39;Au&#39;</span><span class="p">,</span> <span class="s1">&#39;Hg&#39;</span><span class="p">,</span> <span class="s1">&#39;Tl&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Pb&#39;</span><span class="p">,</span> <span class="s1">&#39;Bi&#39;</span><span class="p">,</span> <span class="s1">&#39;Po&#39;</span><span class="p">,</span> <span class="s1">&#39;At&#39;</span><span class="p">,</span> <span class="s1">&#39;Rn&#39;</span><span class="p">,</span> <span class="s1">&#39;Fr&#39;</span><span class="p">,</span> <span class="s1">&#39;Ra&#39;</span><span class="p">,</span> <span class="s1">&#39;Rf&#39;</span><span class="p">,</span> <span class="s1">&#39;Db&#39;</span><span class="p">,</span> <span class="s1">&#39;Sg&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Bh&#39;</span><span class="p">,</span> <span class="s1">&#39;Hs&#39;</span><span class="p">,</span> <span class="s1">&#39;Mt&#39;</span><span class="p">,</span> <span class="s1">&#39;Ds&#39;</span><span class="p">,</span> <span class="s1">&#39;Rg&#39;</span><span class="p">,</span> <span class="s1">&#39;Cn&#39;</span><span class="p">,</span> <span class="s1">&#39;Fl&#39;</span><span class="p">,</span> <span class="s1">&#39;Lv&#39;</span><span class="p">,</span> <span class="s1">&#39;La&#39;</span><span class="p">,</span> <span class="s1">&#39;Ce&#39;</span><span class="p">,</span> <span class="s1">&#39;Pr&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Nd&#39;</span><span class="p">,</span> <span class="s1">&#39;Pm&#39;</span><span class="p">,</span> <span class="s1">&#39;Sm&#39;</span><span class="p">,</span> <span class="s1">&#39;Eu&#39;</span><span class="p">,</span> <span class="s1">&#39;Gd&#39;</span><span class="p">,</span> <span class="s1">&#39;Tb&#39;</span><span class="p">,</span> <span class="s1">&#39;Dy&#39;</span><span class="p">,</span> <span class="s1">&#39;Ho&#39;</span><span class="p">,</span> <span class="s1">&#39;Er&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;Yb&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Lu&#39;</span><span class="p">,</span> <span class="s1">&#39;Ac&#39;</span><span class="p">,</span> <span class="s1">&#39;Th&#39;</span><span class="p">,</span> <span class="s1">&#39;Pa&#39;</span><span class="p">,</span> <span class="s1">&#39;U&#39;</span><span class="p">,</span> <span class="s1">&#39;Np&#39;</span><span class="p">,</span> <span class="s1">&#39;Pu&#39;</span><span class="p">,</span> <span class="s1">&#39;Am&#39;</span><span class="p">,</span> <span class="s1">&#39;Cm&#39;</span><span class="p">,</span> <span class="s1">&#39;Bk&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Cf&#39;</span><span class="p">,</span> <span class="s1">&#39;Es&#39;</span><span class="p">,</span> <span class="s1">&#39;Fm&#39;</span><span class="p">,</span> <span class="s1">&#39;Md&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Lr&#39;</span><span class="p">]</span>
<span class="n">ATOM_SYMBOLS_FEATURE</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="s1">&#39;atom_symbol&#39;</span><span class="p">,</span> <span class="n">ATOM_SYMBOLS</span><span class="p">)</span>

<span class="n">ATOM_AROMATIC_VALUES</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="n">ATOM_AROMATIC_FEATURE</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="s1">&#39;is_aromatic&#39;</span><span class="p">,</span> <span class="n">ATOM_AROMATIC_VALUES</span><span class="p">)</span>

<span class="c1"># In practice you might like to use categroical features for valence, but we use continuous here for demonstration</span>
<span class="n">ATOM_EXPLICIT_VALENCE_FEATURE</span> <span class="o">=</span> <span class="n">ContinuousVariable</span><span class="p">(</span><span class="s1">&#39;explicit_valence&#39;</span><span class="p">)</span>

<span class="n">ATOM_IMPLICIT_VALENCE_FEATURE</span> <span class="o">=</span> <span class="n">ContinuousVariable</span><span class="p">(</span><span class="s1">&#39;implicit_valence&#39;</span><span class="p">)</span>

<span class="n">ATOM_FEATURES</span> <span class="o">=</span> <span class="p">[</span><span class="n">ATOM_SYMBOLS_FEATURE</span><span class="p">,</span> <span class="n">ATOM_AROMATIC_FEATURE</span><span class="p">,</span> <span class="n">ATOM_EXPLICIT_VALENCE_FEATURE</span><span class="p">,</span> <span class="n">ATOM_IMPLICIT_VALENCE_FEATURE</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">get_atom_features</span><span class="p">(</span><span class="n">rd_atom</span><span class="p">):</span>
  <span class="n">atom_symbol</span> <span class="o">=</span> <span class="n">rd_atom</span><span class="o">.</span><span class="n">GetSymbol</span><span class="p">()</span>
  <span class="n">is_aromatic</span> <span class="o">=</span> <span class="n">rd_atom</span><span class="o">.</span><span class="n">GetIsAromatic</span><span class="p">()</span>
  <span class="n">implicit_valence</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">rd_atom</span><span class="o">.</span><span class="n">GetImplicitValence</span><span class="p">())</span>
  <span class="n">explicit_valence</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">rd_atom</span><span class="o">.</span><span class="n">GetExplicitValence</span><span class="p">())</span>
  <span class="k">return</span> <span class="p">{</span><span class="n">ATOM_SYMBOLS_FEATURE</span><span class="p">:</span> <span class="n">atom_symbol</span><span class="p">,</span>
          <span class="n">ATOM_AROMATIC_FEATURE</span><span class="p">:</span> <span class="n">is_aromatic</span><span class="p">,</span>
          <span class="n">ATOM_EXPLICIT_VALENCE_FEATURE</span><span class="p">:</span> <span class="n">explicit_valence</span><span class="p">,</span>
          <span class="n">ATOM_IMPLICIT_VALENCE_FEATURE</span><span class="p">:</span> <span class="n">implicit_valence</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We could use the RDKit enumeration types instead of strings, but the advantage</span>
<span class="c1"># of doing it like this is that our representation becomes independent of RDKit</span>
<span class="n">BOND_TYPES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;UNSPECIFIED&#39;</span><span class="p">,</span> <span class="s1">&#39;SINGLE&#39;</span><span class="p">,</span> <span class="s1">&#39;DOUBLE&#39;</span><span class="p">,</span> <span class="s1">&#39;TRIPLE&#39;</span><span class="p">,</span> <span class="s1">&#39;QUADRUPLE&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;QUINTUPLE&#39;</span><span class="p">,</span> <span class="s1">&#39;HEXTUPLE&#39;</span><span class="p">,</span> <span class="s1">&#39;ONEANDAHALF&#39;</span><span class="p">,</span> <span class="s1">&#39;TWOANDAHALF&#39;</span><span class="p">,</span>
              <span class="s1">&#39;THREEANDAHALF&#39;</span><span class="p">,</span><span class="s1">&#39;FOURANDAHALF&#39;</span><span class="p">,</span> <span class="s1">&#39;FIVEANDAHALF&#39;</span><span class="p">,</span> <span class="s1">&#39;AROMATIC&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;IONIC&#39;</span><span class="p">,</span> <span class="s1">&#39;HYDROGEN&#39;</span><span class="p">,</span> <span class="s1">&#39;THREECENTER&#39;</span><span class="p">,</span>	<span class="s1">&#39;DATIVEONE&#39;</span><span class="p">,</span> <span class="s1">&#39;DATIVE&#39;</span><span class="p">,</span>
              <span class="s1">&#39;DATIVEL&#39;</span><span class="p">,</span> <span class="s1">&#39;DATIVER&#39;</span><span class="p">,</span> <span class="s1">&#39;OTHER&#39;</span><span class="p">,</span> <span class="s1">&#39;ZERO&#39;</span><span class="p">]</span>
<span class="n">TYPE_FEATURE</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="s1">&#39;bond_type&#39;</span><span class="p">,</span> <span class="n">BOND_TYPES</span><span class="p">)</span>

<span class="n">BOND_DIRECTIONS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span> <span class="s1">&#39;BEGINWEDGE&#39;</span><span class="p">,</span> <span class="s1">&#39;BEGINDASH&#39;</span><span class="p">,</span> <span class="s1">&#39;ENDDOWNRIGHT&#39;</span><span class="p">,</span> <span class="s1">&#39;ENDUPRIGHT&#39;</span><span class="p">,</span> <span class="s1">&#39;EITHERDOUBLE&#39;</span> <span class="p">]</span>
<span class="n">DIRECTION_FEATURE</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="s1">&#39;bond_direction&#39;</span><span class="p">,</span> <span class="n">BOND_DIRECTIONS</span><span class="p">)</span>

<span class="n">BOND_STEREO</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;STEREONONE&#39;</span><span class="p">,</span> <span class="s1">&#39;STEREOANY&#39;</span><span class="p">,</span> <span class="s1">&#39;STEREOZ&#39;</span><span class="p">,</span> <span class="s1">&#39;STEREOE&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;STEREOCIS&#39;</span><span class="p">,</span> <span class="s1">&#39;STEREOTRANS&#39;</span><span class="p">]</span>
<span class="n">STEREO_FEATURE</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="s1">&#39;bond_stereo&#39;</span><span class="p">,</span> <span class="n">BOND_STEREO</span><span class="p">)</span>

<span class="n">AROMATIC_VALUES</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="n">AROMATIC_FEATURE</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="s1">&#39;is_aromatic&#39;</span><span class="p">,</span> <span class="n">AROMATIC_VALUES</span><span class="p">)</span>

<span class="n">BOND_FEATURES</span> <span class="o">=</span> <span class="p">[</span><span class="n">TYPE_FEATURE</span><span class="p">,</span> <span class="n">DIRECTION_FEATURE</span><span class="p">,</span> <span class="n">AROMATIC_FEATURE</span><span class="p">,</span> <span class="n">STEREO_FEATURE</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">get_bond_features</span><span class="p">(</span><span class="n">rd_bond</span><span class="p">):</span>
  <span class="n">bond_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetBondType</span><span class="p">())</span>
  <span class="n">bond_stereo_info</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetStereo</span><span class="p">())</span>
  <span class="n">bond_direction</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetBondDir</span><span class="p">())</span>
  <span class="n">is_aromatic</span> <span class="o">=</span> <span class="n">rd_bond</span><span class="o">.</span><span class="n">GetIsAromatic</span><span class="p">()</span>
  <span class="k">return</span> <span class="p">{</span><span class="n">TYPE_FEATURE</span><span class="p">:</span> <span class="n">bond_type</span><span class="p">,</span>
          <span class="n">DIRECTION_FEATURE</span><span class="p">:</span> <span class="n">bond_direction</span><span class="p">,</span>
          <span class="n">AROMATIC_FEATURE</span><span class="p">:</span> <span class="n">is_aromatic</span><span class="p">,</span>
          <span class="n">STEREO_FEATURE</span><span class="p">:</span> <span class="n">bond_stereo_info</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rdmol_to_graph</span><span class="p">(</span><span class="n">mol</span><span class="p">):</span>
  <span class="n">atoms</span> <span class="o">=</span> <span class="p">{</span><span class="n">rd_atom</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">():</span> <span class="n">get_atom_features</span><span class="p">(</span><span class="n">rd_atom</span><span class="p">)</span> <span class="k">for</span> <span class="n">rd_atom</span> <span class="ow">in</span> <span class="n">mol</span><span class="o">.</span><span class="n">GetAtoms</span><span class="p">()}</span>
  <span class="n">bonds</span> <span class="o">=</span> <span class="p">{</span><span class="nb">frozenset</span><span class="p">((</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetBeginAtomIdx</span><span class="p">(),</span> <span class="n">rd_bond</span><span class="o">.</span><span class="n">GetEndAtomIdx</span><span class="p">())):</span> <span class="n">get_bond_features</span><span class="p">(</span><span class="n">rd_bond</span><span class="p">)</span> <span class="k">for</span> <span class="n">rd_bond</span> <span class="ow">in</span> <span class="n">mol</span><span class="o">.</span><span class="n">GetBonds</span><span class="p">()}</span>
  <span class="k">return</span> <span class="n">atoms</span><span class="p">,</span> <span class="n">bonds</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">smiles_to_graph</span><span class="p">(</span><span class="n">smiles</span><span class="p">):</span>
  <span class="n">rd_mol</span> <span class="o">=</span> <span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">rdmol_to_graph</span><span class="p">(</span><span class="n">rd_mol</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">graph</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">smiles_to_graph</span><span class="p">(</span><span class="s1">&#39;c1ccccc1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GraphDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">graphs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">node_variables</span><span class="p">,</span> <span class="n">edge_variables</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Create a new graph dataset, </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">graphs</span> <span class="o">=</span> <span class="n">graphs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graphs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="s2">&quot;The graphs and labels lists must be the same length&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">metadata</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graphs</span><span class="p">),</span> <span class="s2">&quot;The metadata list needs to be as long as the graphs&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">node_variables</span> <span class="o">=</span> <span class="n">node_variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">edge_variables</span> <span class="o">=</span> <span class="n">edge_variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_variables</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">CategoricalVariable</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_variables</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">ContinuousVariable</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_variables</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">CategoricalVariable</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_variables</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">ContinuousVariable</span><span class="p">)]</span>

  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graphs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">make_continuous_node_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span>
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">)</span>
    <span class="n">continuous_node_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float_type</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node_idx</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">nodes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">node_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">features</span><span class="p">[</span><span class="n">continuous_feature</span><span class="p">]</span> <span class="k">for</span> <span class="n">continuous_feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float_type</span><span class="p">)</span>
      <span class="n">continuous_node_features</span><span class="p">[</span><span class="n">node_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_features</span>
    <span class="k">return</span> <span class="n">continuous_node_features</span>
      
  <span class="k">def</span> <span class="nf">make_categorical_node_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span>
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">)</span>
    <span class="n">categorical_node_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">categorical_type</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">node_idx</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">nodes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">categorical_variable</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">):</span>
          <span class="n">value</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">categorical_variable</span><span class="p">]</span>
          <span class="n">value_index</span> <span class="o">=</span> <span class="n">categorical_variable</span><span class="o">.</span><span class="n">value_to_idx</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
          <span class="n">categorical_node_features</span><span class="p">[</span><span class="n">node_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_index</span>

    <span class="k">return</span> <span class="n">categorical_node_features</span>

  <span class="k">def</span> <span class="nf">make_continuous_edge_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">)</span>
    <span class="n">continuous_edge_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float_type</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">edge</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">edges</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">edge_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">features</span><span class="p">[</span><span class="n">continuous_feature</span><span class="p">]</span> <span class="k">for</span> <span class="n">continuous_feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float_type</span><span class="p">)</span>
      <span class="n">u</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">edge</span>
      <span class="n">continuous_edge_features</span><span class="p">[</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_features</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">Set</span><span class="p">):</span>
        <span class="n">continuous_edge_features</span><span class="p">[</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_features</span>

    <span class="k">return</span> <span class="n">continuous_edge_features</span>

  <span class="k">def</span> <span class="nf">make_categorical_edge_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">)</span>
    <span class="n">categorical_edge_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">categorical_type</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">edge</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="n">edges</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">u</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">edge</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">categorical_variable</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">):</span>
          <span class="n">value</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">categorical_variable</span><span class="p">]</span>
          <span class="n">value_index</span> <span class="o">=</span> <span class="n">categorical_variable</span><span class="o">.</span><span class="n">value_to_idx</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
          <span class="n">categorical_edge_features</span><span class="p">[</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_index</span>
          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">Set</span><span class="p">):</span>
            <span class="n">categorical_edge_features</span><span class="p">[</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_index</span>

    <span class="k">return</span> <span class="n">categorical_edge_features</span>
  
  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># This is where the important stuff happens. We use our node and </span>
    <span class="c1"># edge variable attributes to select what node and edge features to use.</span>
    <span class="c1"># In practice, we often do this as a pre-processing step, but here we do it </span>
    <span class="c1"># in the getitem function for clarity</span>

    <span class="n">graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graphs</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="n">nodes</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">graph</span>
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
    <span class="n">continuous_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_continuous_node_features</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
    <span class="n">categorical_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_categorical_node_features</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
    <span class="n">continuous_edge_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_continuous_edge_features</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">edges</span><span class="p">)</span>
    <span class="n">categorical_edge_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_categorical_edge_features</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">edges</span><span class="p">)</span>

    <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="n">nodes_idx</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">edge_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">edges</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
    <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float_type</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
      <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">edge</span>
      <span class="n">adjacency_matrix</span><span class="p">[</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">Set</span><span class="p">):</span>
        <span class="c1"># This edge is unordered, assume this is a undirected graph</span>
        <span class="n">adjacency_matrix</span><span class="p">[</span><span class="n">v</span><span class="p">,</span><span class="n">u</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">adjacency_list</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
      <span class="n">u</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">edge</span>
      <span class="n">adjacency_list</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
      <span class="c1"># Assume undirected graph is the edge is a set</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">Set</span><span class="p">):</span>
        <span class="n">adjacency_list</span><span class="p">[</span><span class="n">v</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

    <span class="n">data_record</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nodes&#39;</span><span class="p">:</span> <span class="n">nodes_idx</span><span class="p">,</span>
                   <span class="s1">&#39;adjacency_matrix&#39;</span><span class="p">:</span> <span class="n">adjacency_matrix</span><span class="p">,</span>
                   <span class="s1">&#39;adjacency_list&#39;</span><span class="p">:</span> <span class="n">adjacency_list</span><span class="p">,</span>
                   <span class="s1">&#39;categorical_node_features&#39;</span><span class="p">:</span> <span class="n">categorical_node_features</span><span class="p">,</span>
                   <span class="s1">&#39;continuous_node_features&#39;</span><span class="p">:</span> <span class="n">continuous_node_features</span><span class="p">,</span>
                   <span class="s1">&#39;categorical_edge_features&#39;</span><span class="p">:</span> <span class="n">categorical_edge_features</span><span class="p">,</span>
                   <span class="s1">&#39;continuous_edge_features&#39;</span><span class="p">:</span> <span class="n">continuous_edge_features</span><span class="p">,</span>
                   <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">label</span><span class="p">}</span>

    <span class="c1"># If you need to add extra information (metadata about this graph) you can </span>
    <span class="c1"># add an extra key-value pair here. The advantage of using a dict compared </span>
    <span class="c1"># to a tuple is that the downstreams code doesn&#39;t break as long as at least </span>
    <span class="c1"># the expected keys are present. The downside is that using a dict adds </span>
    <span class="c1"># overhead (accessing a dict compared to unpacking a tuple).</span>
    <span class="c1"># A more robust implementation might actually make a separate class for </span>
    <span class="c1"># dataset entires</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">data_record</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">data_record</span>

  <span class="k">def</span> <span class="nf">get_node_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;continuous&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">,</span>
            <span class="s1">&#39;categorical&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">}</span>
  
  <span class="k">def</span> <span class="nf">get_edge_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;continuous&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">,</span>
            <span class="s1">&#39;categorical&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_molecular_graph_dataset</span><span class="p">(</span><span class="n">smiles_records</span><span class="p">,</span> <span class="n">atom_features</span><span class="o">=</span><span class="n">ATOM_FEATURES</span><span class="p">,</span> <span class="n">bond_features</span><span class="o">=</span><span class="n">BOND_FEATURES</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  Create a new GraphDataset from a list of smiles_records dictionaries.</span>
<span class="sd">  These records should contain the key &#39;smiles&#39; and &#39;label&#39;. Any other keys will be saved as a &#39;metadata&#39; record.</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">graphs</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">smiles_record</span> <span class="ow">in</span> <span class="n">smiles_records</span><span class="p">:</span>
    <span class="n">smiles</span> <span class="o">=</span> <span class="n">smiles_record</span><span class="p">[</span><span class="s1">&#39;smiles&#39;</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">smiles_record</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">smiles_to_graph</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
    <span class="n">graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smiles_record</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">GraphDataset</span><span class="p">(</span><span class="n">graphs</span><span class="o">=</span><span class="n">graphs</span><span class="p">,</span> 
                      <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> 
                      <span class="n">node_variables</span><span class="o">=</span><span class="n">atom_features</span><span class="p">,</span> 
                      <span class="n">edge_variables</span><span class="o">=</span><span class="n">bond_features</span><span class="p">,</span> 
                      <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">)</span>
  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">make_molecular_graph_dataset</span><span class="p">([{</span><span class="s1">&#39;smiles&#39;</span><span class="p">:</span> <span class="s1">&#39;c1ccccc1&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">},{</span><span class="s1">&#39;smiles&#39;</span><span class="p">:</span><span class="s1">&#39;OS(=O)(=O)O&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Set</span> <span class="c1"># We assume that edges as sets are for undirected graphs</span>

<span class="k">def</span> <span class="nf">collate_graph_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&#39;&#39;&#39;Collate a batch of graph dictionaries produdce by a GraphDataset&#39;&#39;&#39;</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

  <span class="n">max_nodes</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">graph</span><span class="p">[</span><span class="s1">&#39;nodes&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">graph</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
  
  <span class="c1"># We start by allocating the tensors we&#39;ll use. We defer allocating feature</span>
  <span class="c1"># tensors until we know the graphs actually has those kinds of features.</span>
  <span class="n">adjacency_matrices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float_type</span><span class="p">)</span>
  <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">graph</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">graph</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">labels_type</span><span class="p">)</span>
  <span class="n">stacked_continuous_node_features</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">stacked_categorical_node_features</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">stacked_continuous_edge_features</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">stacked_categorical_edge_features</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="n">nodes_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mask_type</span><span class="p">)</span>
  <span class="n">edge_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mask_type</span><span class="p">)</span>
  
  <span class="n">has_metadata</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">graph</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;metadata&#39;</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">:</span>
      <span class="n">has_metadata</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="c1"># We&#39;ll take basic information about the different graphs from the adjacency </span>
    <span class="c1"># matrix</span>
    <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;adjacency_matrix&#39;</span><span class="p">]</span>
    <span class="n">g_nodes</span><span class="p">,</span> <span class="n">g_nodes</span> <span class="o">=</span> <span class="n">adjacency_matrix</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">adjacency_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency_matrix</span>

    <span class="c1"># Now when we know how many of the entries are valid, we set those to 1s in</span>
    <span class="c1"># the masks</span>
    <span class="n">edge_mask</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">nodes_mask</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    

    <span class="c1"># All the feature constructions follow the same recipie. We essentially</span>
    <span class="c1"># locate the entries in the stacked feature tensor (containing all graphs)</span>
    <span class="c1"># and set it with the features from the current graph.</span>
    <span class="n">g_continuous_node_features</span> <span class="o">=</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;continuous_node_features&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">g_continuous_node_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">stacked_continuous_node_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g_nodes</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">g_continuous_node_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">stacked_continuous_node_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
      <span class="n">stacked_continuous_node_features</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="n">g_continuous_node_features</span>
    
    <span class="n">g_categorical_node_features</span> <span class="o">=</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;categorical_node_features&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">g_categorical_node_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">stacked_categorical_node_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g_nodes</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">g_categorical_node_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">stacked_categorical_node_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">categorical_type</span><span class="p">)</span>
      <span class="n">stacked_categorical_node_features</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="n">g_categorical_node_features</span>

    <span class="n">g_continuous_edge_features</span> <span class="o">=</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;continuous_edge_features&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">g_continuous_edge_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">stacked_continuous_edge_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g_nodes</span><span class="p">,</span> <span class="n">g_nodes</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">g_continuous_edge_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">stacked_continuous_edge_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
      <span class="n">stacked_continuous_edge_features</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="n">g_continuous_edge_features</span>

    <span class="n">g_categorical_edge_features</span> <span class="o">=</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;categorical_edge_features&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">g_categorical_edge_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">stacked_categorical_edge_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g_nodes</span><span class="p">,</span> <span class="n">g_nodes</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">g_categorical_edge_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">stacked_categorical_edge_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">,</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">categorical_type</span><span class="p">)</span>
      <span class="n">stacked_categorical_edge_features</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">,</span> <span class="p">:</span><span class="n">g_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="n">g_categorical_edge_features</span>


  <span class="n">batch_record</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;adjacency_matrices&#39;</span><span class="p">:</span> <span class="n">adjacency_matrices</span><span class="p">,</span>
          <span class="s1">&#39;categorical_node_features&#39;</span><span class="p">:</span> <span class="n">stacked_categorical_node_features</span><span class="p">,</span>
          <span class="s1">&#39;continuous_node_features&#39;</span><span class="p">:</span> <span class="n">stacked_continuous_node_features</span><span class="p">,</span>
          <span class="s1">&#39;categorical_edge_features&#39;</span><span class="p">:</span> <span class="n">stacked_categorical_edge_features</span><span class="p">,</span>
          <span class="s1">&#39;continuous_edge_features&#39;</span><span class="p">:</span> <span class="n">stacked_continuous_edge_features</span><span class="p">,</span>
          <span class="s1">&#39;nodes_mask&#39;</span><span class="p">:</span> <span class="n">nodes_mask</span><span class="p">,</span>
          <span class="s1">&#39;edge_mask&#39;</span><span class="p">:</span> <span class="n">edge_mask</span><span class="p">,</span>
          <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>
  <span class="k">if</span> <span class="n">has_metadata</span><span class="p">:</span>
    <span class="n">batch_record</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;metadata&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">batch_record</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_batch</span> <span class="o">=</span> <span class="n">collate_graph_batch</span><span class="p">([</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="k">class</span> <span class="nc">Embedder</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">categorical_variables</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_variables</span> <span class="o">=</span> <span class="n">categorical_variables</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">categorical_variables</span><span class="p">:</span>
      <span class="n">num_embeddings</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">has_null_value</span><span class="p">:</span>
        <span class="c1"># It&#39;s not uncommon to have missing values, we support this assinging a special 0-index which have the zero-vector as its embedding</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">var</span><span class="o">.</span><span class="n">get_null_idx</span><span class="p">())</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
      <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">ModuleList</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
    
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">):</span>
    <span class="c1"># The node features is a matrix with as many rows as nodes of our graph</span>
    <span class="c1"># and as many columns as we have categorical features</span>
    <span class="n">all_embedded_vars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">):</span>
      <span class="c1"># We pick out just the i&#39;th column. The ellipsis &#39;...&#39; in a numpy-style </span>
      <span class="c1"># slice is a useful way of saying you want full range over all other axises</span>
      <span class="c1"># We use it so that this can actually take a categorical_features array</span>
      <span class="c1"># with arbitrary number of trailing axises to support both the node </span>
      <span class="c1"># features, the edge features and the mini-batched version of both</span>
      <span class="n">var_indices</span> <span class="o">=</span> <span class="n">categorical_features</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>  
      <span class="n">embedded_vars</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="n">var_indices</span><span class="p">)</span>
      <span class="n">all_embedded_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embedded_vars</span><span class="p">)</span>

    <span class="c1"># If you like, you can implement concatenation instead of sum here</span>
    <span class="n">stacked_embedded_vars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">all_embedded_vars</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">embedded_vars</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">stacked_embedded_vars</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">embedded_vars</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeatureCombiner</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">categorical_variables</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_variables</span> <span class="o">=</span> <span class="n">categorical_variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span> <span class="o">=</span> <span class="n">Embedder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_variables</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">continuous_features</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">,</span> <span class="p">):</span>
    <span class="c1"># We need to be agnostic to whether we have categorical features and continuous features (it&#39;s not uncommon to only use one kind)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">categorical_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">embedded_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedder</span><span class="p">(</span><span class="n">categorical_features</span><span class="p">)</span>
      <span class="n">features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embedded_features</span><span class="p">)</span>
      <span class="c1"># The embedded features are now of shape (n_nodes, embedding_dim)</span>
    <span class="k">if</span> <span class="n">continuous_features</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">continuous_features</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;No features to combine&#39;</span><span class="p">)</span>
    <span class="n">full_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Now we concatenate along the feature dimension</span>
    <span class="k">return</span> <span class="n">full_features</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-step">
<h2>Training step<a class="headerlink" href="#training-step" title="Permalink to this heading"></a></h2>
<p>This section downloads the data and implements the training procedures. This code should also be familiar from the previous lessons.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">deque</span> <span class="c1"># We&#39;ll use this to construct the dataset splits</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem.Scaffolds.MurckoScaffold</span> <span class="kn">import</span> <span class="n">MurckoScaffoldSmilesFromSmiles</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">potential_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;BBBP.csv&#39;</span><span class="p">),</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;../dataset/BBBP.csv&#39;</span><span class="p">)]</span>
<span class="n">bbbp_table</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">potential_paths</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="n">bbbp_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">break</span>
<span class="n">bbbp_table</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
      <th>name</th>
      <th>p_np</th>
      <th>smiles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Propanolol</td>
      <td>1</td>
      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Terbutylchlorambucil</td>
      <td>1</td>
      <td>C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>40730</td>
      <td>1</td>
      <td>c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>24</td>
      <td>1</td>
      <td>C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>cloxacillin</td>
      <td>1</td>
      <td>Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2045</th>
      <td>2049</td>
      <td>licostinel</td>
      <td>1</td>
      <td>C1=C(Cl)C(=C(C2=C1NC(=O)C(N2)=O)[N+](=O)[O-])Cl</td>
    </tr>
    <tr>
      <th>2046</th>
      <td>2050</td>
      <td>ademetionine(adenosyl-methionine)</td>
      <td>1</td>
      <td>[C@H]3([N]2C1=C(C(=NC=N1)N)N=C2)[C@@H]([C@@H](...</td>
    </tr>
    <tr>
      <th>2047</th>
      <td>2051</td>
      <td>mesocarb</td>
      <td>1</td>
      <td>[O+]1=N[N](C=C1[N-]C(NC2=CC=CC=C2)=O)C(CC3=CC=...</td>
    </tr>
    <tr>
      <th>2048</th>
      <td>2052</td>
      <td>tofisoline</td>
      <td>1</td>
      <td>C1=C(OC)C(=CC2=C1C(=[N+](C(=C2CC)C)[NH-])C3=CC...</td>
    </tr>
    <tr>
      <th>2049</th>
      <td>2053</td>
      <td>azidamfenicol</td>
      <td>1</td>
      <td>[N+](=NCC(=O)N[C@@H]([C@H](O)C1=CC=C([N+]([O-]...</td>
    </tr>
  </tbody>
</table>
<p>2050 rows × 4 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># There are about 50 problematic SMILES. We&#39;ve supressed RDKit logger outputs</span>
<span class="c1"># but if you haven&#39;t you&#39;ll get a lot of printouts here</span>
<span class="c1"># 11 SMILES can&#39;t be processed at all so we throw them away</span>

<span class="n">smiles_records</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">p_np</span><span class="p">,</span> <span class="n">smiles</span> <span class="ow">in</span> <span class="n">bbbp_table</span><span class="o">.</span><span class="n">to_records</span><span class="p">():</span>
  <span class="c1"># check if RDKit accepts this smiles</span>
  <span class="k">if</span> <span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">smiles_record</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;smiles&#39;</span><span class="p">:</span> <span class="n">smiles</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">p_np</span><span class="p">,</span> <span class="s1">&#39;metadata&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;row&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">}}</span>
    <span class="n">smiles_records</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smiles_record</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Molecule </span><span class="si">{</span><span class="n">smiles</span><span class="si">}</span><span class="s1"> on row </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> could not be parsed by RDKit&#39;</span><span class="p">)</span>
  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Molecule O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3 on row 59 could not be parsed by RDKit
Molecule c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC on row 61 could not be parsed by RDKit
Molecule Cc1nc(sc1)\[NH]=C(\N)N on row 391 could not be parsed by RDKit
Molecule s1cc(CSCCN\C(NC)=[NH]\C#N)nc1\[NH]=C(\N)N on row 614 could not be parsed by RDKit
Molecule c1c(c(ncc1)CSCCN\C(=[NH]\C#N)NCC)Br on row 642 could not be parsed by RDKit
Molecule n1c(csc1\[NH]=C(\N)N)c1ccccc1 on row 645 could not be parsed by RDKit
Molecule n1c(csc1\[NH]=C(\N)N)c1cccc(c1)N on row 646 could not be parsed by RDKit
Molecule n1c(csc1\[NH]=C(\N)N)c1cccc(c1)NC(C)=O on row 647 could not be parsed by RDKit
Molecule n1c(csc1\[NH]=C(\N)N)c1cccc(c1)N\C(NC)=[NH]\C#N on row 648 could not be parsed by RDKit
Molecule s1cc(nc1\[NH]=C(\N)N)C on row 649 could not be parsed by RDKit
Molecule c1(cc(N\C(=[NH]\c2cccc(c2)CC)C)ccc1)CC on row 685 could not be parsed by RDKit
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>

<span class="n">training_fraction</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">dev_fraction</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">n_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">smiles_records</span><span class="p">)</span>
<span class="n">n_training_examples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_examples</span><span class="o">*</span><span class="n">training_fraction</span><span class="p">)</span>
<span class="n">n_dev_examples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_examples</span><span class="o">*</span><span class="n">dev_fraction</span><span class="p">)</span>

<span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_examples</span><span class="p">))</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>  <span class="c1"># shuffle is in place</span>
<span class="n">training_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">n_training_examples</span><span class="p">]</span>
<span class="n">dev_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">n_training_examples</span><span class="p">:</span><span class="n">n_training_examples</span><span class="o">+</span><span class="n">n_dev_examples</span><span class="p">]</span>
<span class="n">test_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">n_training_examples</span><span class="o">+</span><span class="n">n_dev_examples</span><span class="p">:]</span>

<span class="n">training_smiles_records</span> <span class="o">=</span> <span class="p">[</span><span class="n">smiles_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">training_indices</span><span class="p">]</span>
<span class="n">dev_smiles_records</span> <span class="o">=</span> <span class="p">[</span><span class="n">smiles_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dev_indices</span><span class="p">]</span>
<span class="n">test_smiles_records</span> <span class="o">=</span> <span class="p">[</span><span class="n">smiles_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">test_indices</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_graph_dataset</span> <span class="o">=</span> <span class="n">make_molecular_graph_dataset</span><span class="p">(</span><span class="n">training_smiles_records</span><span class="p">)</span>
<span class="n">dev_graph_dataset</span> <span class="o">=</span> <span class="n">make_molecular_graph_dataset</span><span class="p">(</span><span class="n">dev_smiles_records</span><span class="p">)</span>
<span class="n">test_graph_dataset</span> <span class="o">=</span> <span class="n">make_molecular_graph_dataset</span><span class="p">(</span><span class="n">test_smiles_records</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">num_dataloader_workers</span><span class="o">=</span><span class="mi">2</span> <span class="c1"># The colab instances are very limited in number of cpus</span>

<span class="n">training_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">training_graph_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                          <span class="n">num_workers</span><span class="o">=</span><span class="n">num_dataloader_workers</span><span class="p">,</span> 
                                          <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_graph_batch</span><span class="p">)</span>
<span class="n">dev_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dev_graph_dataset</span><span class="p">,</span> 
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">num_workers</span><span class="o">=</span><span class="n">num_dataloader_workers</span><span class="p">,</span> 
                                     <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_graph_batch</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_graph_dataset</span><span class="p">,</span> 
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">num_workers</span><span class="o">=</span><span class="n">num_dataloader_workers</span><span class="p">,</span> 
                                     <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_graph_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GraphPredictionHeadConfig</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">):</span>
    <span class="c1"># Pooling type can be &#39;sum&#39; or &#39;mean&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dim</span> <span class="o">=</span> <span class="n">ffn_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pooling_type</span> <span class="o">=</span> <span class="n">pooling_type</span>

<span class="k">class</span> <span class="nc">GraphPredictionHead</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">),</span> 
                                <span class="n">ReLU</span><span class="p">(),</span> 
                                <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_features</span><span class="p">,</span> <span class="n">node_mask</span><span class="p">):</span>
    <span class="c1"># The node_features is a tensor of shape (*leading_axises, max_nodes, d_model)</span>
    <span class="c1"># We want to &#39;pool&#39; this along the node-axis, which is dim=-2 in pytorch terms</span>
    <span class="c1"># In this case we assume these features are valid, i.e. that they have been</span>
    <span class="c1"># masked at a previous step.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pooling_type</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
      <span class="n">pooled_nodes</span> <span class="o">=</span> <span class="n">node_features</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pooling_type</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
      <span class="c1"># We can&#39;t take just the mean along dim=-2, since if this is a batch, some of </span>
      <span class="c1"># the graphs need to be divided by a smaller number than max_nodes. </span>
      <span class="c1"># Thankfully we have the information about how many nodes each graph has in</span>
      <span class="c1"># the node_mask, and since it has 1&#39;s and 0&#39;s, just summing it along the </span>
      <span class="c1"># max_nodes axis gives the count of nodes for the corresponding graph</span>
      
      <span class="c1"># node_mask has the shape (batch_size, max_nodes), or just (max_nodes,) </span>
      <span class="c1"># if it&#39;s not a batch. We get the count per graph by reducing along the </span>
      <span class="c1"># last dimension, and by setting keepdims=True, we get a shape </span>
      <span class="c1"># (batch_size, 1) or (1,) which will allow for broadcasting this with </span>
      <span class="c1"># division over the summed feature vectors to calculate their mean </span>
      <span class="n">node_counts</span> <span class="o">=</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  
      <span class="n">summed_feature_vectors</span> <span class="o">=</span> <span class="n">node_features</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
      <span class="n">pooled_nodes</span> <span class="o">=</span> <span class="n">summed_feature_vectors</span><span class="o">/</span><span class="n">node_counts</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unsupported pooling type </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pooling_type</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="p">(</span><span class="n">pooled_nodes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prediction</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">BCEWithLogitsLoss</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Device is&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Device is cuda
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">BCEWithLogitsLoss</span><span class="p">,</span> <span class="n">MSELoss</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">median_absolute_error</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
  <span class="n">moved_batch</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">moved_batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
  <span class="k">return</span> <span class="n">moved_batch</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> 
               <span class="n">loss_fn</span><span class="p">,</span> <span class="n">training_dataloader</span><span class="p">,</span> 
               <span class="n">dev_dataloader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_dataloader</span> <span class="o">=</span> <span class="n">training_dataloader</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dev_dataloader</span> <span class="o">=</span> <span class="n">dev_dataloader</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">as</span> <span class="n">epoch_progress</span><span class="p">:</span>
      <span class="n">batches_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_dataloader</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dev_dataloader</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epoch_progress</span><span class="p">:</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">training_batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Training batch&#39;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="c1"># Move all tensors to the device</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
          <span class="n">training_batch</span> <span class="o">=</span> <span class="n">batch_to_device</span><span class="p">(</span><span class="n">training_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
          <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">training_batch</span><span class="p">)</span>
          <span class="n">labels</span> <span class="o">=</span> <span class="n">training_batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># By default the predictions have shape (batch_size, 1)</span>
          <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
          <span class="n">batch_n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
          <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">batch_n</span> <span class="o">*</span> <span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
          <span class="n">train_n</span> <span class="o">+=</span> <span class="n">batch_n</span>
        <span class="c1">#print(f&quot;Training loss for epoch {total_epochs}&quot;, train_loss/train_n)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">dev_predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dev_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dev_n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dev_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dev_batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dev_dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Dev batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
          <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dev_batch</span> <span class="o">=</span> <span class="n">batch_to_device</span><span class="p">(</span><span class="n">dev_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">dev_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">dev_predictions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">dev_batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
            <span class="n">dev_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># By default the predictions have shape (batch_size, 1)</span>
            <span class="n">batch_n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="n">dev_loss</span> <span class="o">+=</span> <span class="n">batch_n</span><span class="o">*</span><span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">dev_n</span> <span class="o">+=</span> <span class="n">batch_n</span>
        <span class="n">epoch_progress</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: train loss </span><span class="si">{</span><span class="n">train_loss</span><span class="o">/</span><span class="n">train_n</span><span class="si">:</span><span class="s2"> .3f</span><span class="si">}</span><span class="s2">, dev loss </span><span class="si">{</span><span class="n">dev_loss</span><span class="o">/</span><span class="n">dev_n</span><span class="si">:</span><span class="s2"> .3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]):</span>
  <span class="n">eval_predictions</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">eval_labels</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">eval_loss</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">eval_n</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model</span>
  <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">loss_fn</span>
  <span class="n">total_epochs</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">eval_batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">)):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">eval_batch</span> <span class="o">=</span> <span class="n">batch_to_device</span><span class="p">(</span><span class="n">eval_batch</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
      <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
      <span class="n">eval_predictions</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">prediction</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
      <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
      <span class="n">eval_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># By default the predictions have shape (batch_size, 1)</span>
      <span class="n">batch_n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
      <span class="n">eval_loss</span> <span class="o">+=</span> <span class="n">batch_n</span><span class="o">*</span><span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
      <span class="n">eval_n</span> <span class="o">+=</span> <span class="n">batch_n</span>
  <span class="n">average_loss</span> <span class="o">=</span> <span class="n">eval_loss</span><span class="o">/</span><span class="n">eval_n</span>
  <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">eval_labels</span><span class="p">,</span> <span class="n">eval_predictions</span><span class="p">)</span>
  <span class="n">eval_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">eval_labels</span><span class="p">,</span> <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="n">eval_predictions</span><span class="p">})</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">eval_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="n">hue_order</span><span class="p">)</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">eval_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">hue_order</span><span class="o">=</span><span class="n">hue_order</span><span class="p">)</span>
  
  <span class="k">if</span> <span class="n">label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> dataset after </span><span class="si">{</span><span class="n">total_epochs</span><span class="si">}</span><span class="s2"> epochs</span><span class="se">\n</span><span class="s2">loss </span><span class="si">{</span><span class="n">average_loss</span><span class="si">}</span><span class="se">\n</span><span class="s2">ROC AUC </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;After </span><span class="si">{</span><span class="n">total_epochs</span><span class="si">}</span><span class="s2"> epochs</span><span class="se">\n</span><span class="s2">loss </span><span class="si">{</span><span class="n">average_loss</span><span class="si">}</span><span class="se">\n</span><span class="s2">ROC AUC </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="from-gnns-to-transformers">
<h2>From GNNs to Transformers<a class="headerlink" href="#from-gnns-to-transformers" title="Permalink to this heading"></a></h2>
<p>We’ve seen how the idea of using sums of vectors can be used to learn things from a graph, we used it on graph neighbourhoods to introduce more structure and we used it as a pooling method for graph predictions. We also saw how the aggregation of a graph neighourhood good be done by multiplying with the adjacency matrix.</p>
<p>We saw how this summing of local neighbourhoods in the graph can be done using a matrix multiplication of the graphs adjacency matrix and the neighbouring node representations</p>
<p>$$ \mathbf{h}<em>i^L = f(\sum</em>{j \in N(i)} \mathbf{h}_j^{L-1}, \mathbf{h}<em>i^{L-1}) $$
$$ \sum</em>{j \in N(i)} \mathbf{h}_j^{L-1} = A_i H^{L-1}$$
$$ H^{L-1} = \begin{bmatrix}\mathbf{h}_1^{L-1}\mathbf{h}_2^{L-1}\vdots\mathbf{h}_n^{L-1}\end{bmatrix} $$</p>
<p>Assuming that the adjacency matrix $A$ is a binary indicator matrix with 1’s for pairs $i,j$ which are connected by an edge, and 0 if they are not connected.</p>
<p>A way to think about the “convolutional” part of a Graph Neural Network is then that it’s essentially performing a matrix multiplication with the adjacency
matrix:
$$H^L = f(AH^{L-1}, H^{L-1})$$</p>
<p>Where $f$ is a function we wish to learn (e.g. a neural network with two input vectors).</p>
<p>The multiplication $AH^{L-1}$ is what takes the graph structure into account by only aggregating the local neighbourhoods. We’ve seen previously how this method has some fundamental limitations, in particular the “convolution” has a receptive field, so is biased towards learning local patterns.</p>
<section id="dynamically-computed-adjacency-matrix">
<h3>Dynamically computed “adjacency matrix”<a class="headerlink" href="#dynamically-computed-adjacency-matrix" title="Permalink to this heading"></a></h3>
<p>What if instead of assuming the matrix A to be the adjacenct matrix, we calcualte it’s values based on the values of the node pairs and the edge? This would effectively mean that we will potentially aggregate “neighbourhoods” which is the complete graph.</p>
<p>$$A = \begin{bmatrix} g(h_1, h_1, e_{1,1})&amp; g(h_1, h_2, e_{1,2}) &amp; \dots  \ \vdots&amp; \ddots &amp; \ g(h_n, h_1, e_{n,1})&amp; \dots &amp; g(h_n, h_n, e_{n,n}) \end{bmatrix}$$</p>
<p>This way we can learn to use node information as well as edge information when deciding on how to aggregate the node set. While it allows us to take the graph structure into account, it also allows the model to learn relationships about more distant nodes.</p>
<p>This is the fundamental idea of the <em>Transformer</em> architecture. By dynamically setting the values of this “adjacency matrix”, we can have a model which can <em>learn</em> to induce structure from arbitrary sets.</p>
<p>Depending on how we construct $g$, we can choose to inject knowledge about the elements of the input set $H$ such as relative position between tokens if H is actually a sequence, or information about a particular pair, such as whether they are connected by an edge in a graph.</p>
</section>
<section id="the-downside">
<h3>The downside<a class="headerlink" href="#the-downside" title="Permalink to this heading"></a></h3>
<p>While this idea is very powerful, it comes with a major limitation. A GNN typically only implictly muiltiply the node vectors $H$ with the adjecency matrix. In practice this is implemented by a <em>sparse</em> operation as we saw in the previous notebook. This means that the computational cost is $O(n d k)$, where $n$ is the number of nodes and $d$ the average (TODO, maximum?) degree and $k$ the dimensionality of the node vectors.</p>
<p>To multiply with a dense matrix this instead becomes $O(n^2 k)$ and this quadratic scaling on the number of nodes in the input severely limits the application of this idea.</p>
<p>Generating $A$ also scales quadratically with the number of nodes, since we need to apply the function to all pairs of node vectors, regardless of edges.</p>
<p>This fact has not stopped this idea of becoming wildly successful in the domain of Natural Language Processing, and as long as the domain we’re working has relatively small inputs (like organic molecules in medicinal chemistry) we can handle the quadratic scaling with input with brute force (a lot of computational capacity).</p>
</section>
<section id="implementing-a-transformer">
<h3>Implementing a Transformer<a class="headerlink" href="#implementing-a-transformer" title="Permalink to this heading"></a></h3>
<p>Below is the implementation of the transformer. In aparticular the <code class="docutils literal notranslate"><span class="pre">BasicTransformerLayer</span></code> is where the main difference from a GNN is implemented. The <code class="docutils literal notranslate"><span class="pre">BasicTransformerEncoder</span></code> is very similar to the GNN encoder.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">,</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">torch.nn.functional</span> <span class="kn">import</span> <span class="n">softmax</span>

<span class="k">class</span> <span class="nc">BasicTransformerConfig</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> 
               <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
               <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
               <span class="n">ffn_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">head_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">layer_normalization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
               <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
               <span class="n">residual_connections</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dim</span> <span class="o">=</span> <span class="n">ffn_dim</span>
    <span class="c1"># Note that we introduce a new hyper parameter called *head_dim*, in</span>
    <span class="c1"># Transformers we typically transform the &quot;node&quot; feature vectors to</span>
    <span class="c1"># a lower dimensional space</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">head_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_normalization</span> <span class="o">=</span> <span class="n">layer_normalization</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span> <span class="o">=</span> <span class="n">residual_connections</span>
    
<span class="k">class</span> <span class="nc">BasicTransformerLayer</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>    
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">head_dim</span>

    <span class="c1"># Transformers typically don&#39;t use mlps to create the neighbours and center</span>
    <span class="c1"># embeddings, instead relying on just linear transformations</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">neighbour_transform</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">center_transform</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="c1"># The transformer uses layer normalization by default</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attention_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">),</span>
                                       <span class="n">ReLU</span><span class="p">(),</span> 
                                       <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">))</span>
                                       
    <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">)</span>
   
    <span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">attention_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">center_node_features</span><span class="p">,</span> 
                         <span class="n">neighbour_node_features</span><span class="p">,</span> <span class="n">edge_features</span><span class="p">,</span> <span class="n">node_mask</span><span class="p">,</span> <span class="n">edge_mask</span><span class="p">):</span>
    <span class="c1">#The standard Transformer just </span>
    <span class="c1"># take the dot product between the center node and the neighbour nodes, </span>
    <span class="c1"># scaled by the square root of the model dimension.</span>
    <span class="c1"># To take the dot products between all center nodes and all neighbour nodes</span>
    <span class="c1"># We perform an outer product by first transposing one of the matrices along</span>
    <span class="c1"># the last two axises</span>
    <span class="c1"># In the single-graph case the matrix multplication between </span>
    <span class="c1"># a matrix with shape (n_nodes, head_dim) times (head_dim, n_nodes)</span>
    <span class="c1"># gives the resulting matrix of shape (n_nodes, n_nodes), where each element</span>
    <span class="c1"># is the dot product of the column for a node in one first with the row of a </span>
    <span class="c1"># node in the other</span>
    <span class="n">attention_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">center_node_features</span><span class="p">,</span> 
                                    <span class="n">neighbour_node_features</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span>

    <span class="c1"># The &quot;adjcency matrix&quot; of the transformer is actually using weighted means</span>
    <span class="c1"># for the aggregation, and the way we achieve this is to make sure that the</span>
    <span class="c1"># rows of the matrix are  normalized using softmax</span>
    <span class="c1"># However, if we have a batch of graphs as inputs, we will have some </span>
    <span class="c1"># &quot;positions&quot; in the node features which we should not include in our </span>
    <span class="c1"># aggregation, and should therefore mask out in our attention matrix.</span>
    <span class="c1"># If we did that after the softmax calculations, the rows would no longer</span>
    <span class="c1"># add up to 1. Instead we do it before the softmax by essentially </span>
    <span class="c1"># setting the masked values to va number so low it will end up as a </span>
    <span class="c1"># 0 in the softmax output. The lowest value we can imagine is negative</span>
    <span class="c1"># infinity, so let&#39;s use that. </span>
    <span class="c1"># The goal is to mask out parts of the different batch attention_logits which</span>
    <span class="c1"># are not part of the nodes, so essentially have a resulting matrix per batch</span>
    <span class="c1"># example which looks something like</span>
    <span class="c1"># [[   a,    b,    c, -inf, -inf],</span>
    <span class="c1">#  [   d,    e,    f, -inf, -inf],</span>
    <span class="c1">#  [   g,    h,    i, -inf, -inf],</span>
    <span class="c1">#  [-inf, -inf, -inf, -inf, -inf],</span>
    <span class="c1">#  [-inf, -inf, -inf, -inf, -inf],</span>
    <span class="c1"># ]</span>
    <span class="c1"># To do this we will first create a boolean mask which have True in the</span>
    <span class="c1"># places we want to fill with &#39;-inf&#39;. We do this by using the node mask</span>
    <span class="c1"># like in the GNN examples, doing something very much like an outer product</span>
    <span class="n">nodemask_2d</span> <span class="o">=</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># The nodemask has 1&#39;s where there are valid elements and 0&#39;s where there </span>
    <span class="c1"># are none, we invert his and convert it to bool tensor</span>
    <span class="n">fill_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nodemask_2d</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    
    <span class="c1"># We&#39;re now ready to &#39;mask out&#39; the logits. Notice that masked_fill_ is </span>
    <span class="c1"># in place</span>
    <span class="n">attention_logits</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">fill_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">))</span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">attention_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># There will be rows of the smaller attention matrices which where filled</span>
    <span class="c1"># completely with -inf values, these will now be rows of &#39;nan&#39; values</span>
    <span class="c1"># We perform a new fill of the attention matrix, but this time with 0s </span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">attention_matrix</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">fill_mask</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attention_matrix</span>


  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">node_features</span><span class="p">,</span> <span class="n">edge_features</span><span class="p">,</span> <span class="n">node_mask</span><span class="p">,</span> <span class="n">edge_mask</span><span class="p">):</span>
    <span class="c1"># In this basic Transformer layer we&#39;ll not use the edge features, and instead</span>
    <span class="c1"># focus on the basic transformer formulation of this problem. This will pretty</span>
    <span class="c1"># much treat the graph as just a node set. We should not expect this to </span>
    <span class="c1"># be able to anything which relies on the graph structure</span>
    <span class="n">center_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_transform</span><span class="p">(</span><span class="n">node_features</span><span class="p">)</span>
    <span class="n">neighbour_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbour_transform</span><span class="p">(</span><span class="n">node_features</span><span class="p">)</span>

    <span class="c1"># The transformed node features are either a 3-tensor </span>
    <span class="c1"># (batch_size, max_nodes, head_dim) or a matrix (n_nodes, head_dim) when</span>
    <span class="c1"># it&#39;s a single graph. We&#39;ll make this code agnostic to that</span>
    <span class="c1"># The goal now is to _compute_ an &quot;adjacency matrix&quot; using the node features</span>
    <span class="c1"># This could be done by any function. We define a method on this class</span>
    <span class="c1"># which is the attention function which has the purpose of giving us an</span>
    <span class="c1"># &quot;adjacency matrix&quot;</span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_function</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> 
                                               <span class="n">center_node_features</span><span class="p">,</span>
                                               <span class="n">neighbour_node_features</span><span class="p">,</span> 
                                               <span class="n">edge_features</span><span class="p">,</span> 
                                               <span class="n">node_mask</span><span class="p">,</span> 
                                               <span class="n">edge_mask</span><span class="p">)</span>
    
    <span class="c1"># Now we aggregate the neighbourhoods using the attention matrix (our computed &quot;adjacency matrix&quot;)</span>
    <span class="c1"># The transformer doesn&#39;t transform the node features at this stage, instead doing it in a separate MLP after residual connections and aggregation</span>
    <span class="n">aggregated_neighbourhoods</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_matrix</span><span class="p">,</span> <span class="n">node_features</span><span class="p">)</span>

    <span class="c1"># and mask the result    </span>
    <span class="n">masked_features</span> <span class="o">=</span> <span class="n">aggregated_neighbourhoods</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Followed by a dropout and layer normalization</span>
    <span class="n">masked_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">masked_features</span><span class="p">)</span>
    <span class="n">masked_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_norm</span><span class="p">(</span><span class="n">masked_features</span><span class="p">)</span>

    <span class="c1"># The transformer by default uses residual connections</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
      <span class="n">masked_features</span> <span class="o">=</span> <span class="n">masked_features</span> <span class="o">+</span> <span class="n">node_features</span>

    <span class="c1"># Now we apply the output transform as in the GNN</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span><span class="p">(</span><span class="n">masked_features</span><span class="p">)</span>

    <span class="c1"># Mask again</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="n">updated_node_features</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Followed by a dropout and normalization</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">updated_node_features</span><span class="p">)</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">updated_node_features</span><span class="p">)</span>

    <span class="c1"># And the resiudal connection from the input to the output MLP</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
      <span class="n">updated_node_features</span> <span class="o">=</span> <span class="n">updated_node_features</span> <span class="o">+</span> <span class="n">masked_features</span>

    <span class="k">return</span> <span class="n">updated_node_features</span>


<span class="k">class</span> <span class="nc">BasicTransformerEncoder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span>
               <span class="n">config</span><span class="p">:</span> <span class="n">BasicTransformerConfig</span><span class="p">,</span> 
               <span class="n">continuous_node_variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">categorical_node_variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">continuous_edge_variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">categorical_edge_variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">layer_type</span><span class="o">=</span><span class="n">BasicTransformerLayer</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">layer_type</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span> <span class="o">=</span> <span class="n">continuous_node_variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span> <span class="o">=</span> <span class="n">categorical_node_variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span> <span class="o">=</span> <span class="n">continuous_edge_variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span> <span class="o">=</span> <span class="n">categorical_edge_variables</span>

    <span class="c1"># We want the embeddings together with the continuous values to be of dimension d_model, therefore the allocate d_model - len(continuous_variables) as the embeddings dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_embeddings_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">d_model</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_embeddings_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">d_model</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">node_featurizer</span> <span class="o">=</span> <span class="n">FeatureCombiner</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">,</span> 
                                           <span class="bp">self</span><span class="o">.</span><span class="n">categorical_node_embeddings_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">edge_featurizer</span> <span class="o">=</span> <span class="n">FeatureCombiner</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">,</span> 
                                           <span class="bp">self</span><span class="o">.</span><span class="n">categorical_edge_embeddings_dim</span><span class="p">)</span>
    
    <span class="c1"># Notice that we use the supplied layer type above when creating the graph</span>
    <span class="c1"># layers. This allows us to easily change the kind of graph layers</span>
    <span class="c1"># we use later on</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">graph_layers</span> <span class="o">=</span> <span class="n">ModuleList</span><span class="p">([</span><span class="n">layer_type</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_layers</span><span class="p">)])</span>
    
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="c1"># First order of business is to embed the node embeddings</span>
    <span class="n">node_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;nodes_mask&#39;</span><span class="p">]</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_nodes</span> <span class="o">=</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="n">continuous_node_features</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;continuous_node_features&#39;</span><span class="p">]</span>
    <span class="n">categorical_node_features</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;categorical_node_features&#39;</span><span class="p">]</span>
    <span class="n">node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_featurizer</span><span class="p">(</span><span class="n">continuous_node_features</span><span class="p">,</span> <span class="n">categorical_node_features</span><span class="p">)</span>
    <span class="n">masked_node_features</span> <span class="o">=</span> <span class="n">node_features</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">continuous_edge_features</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;continuous_edge_features&#39;</span><span class="p">]</span>
    <span class="n">categorical_edge_features</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;categorical_edge_features&#39;</span><span class="p">]</span>
    <span class="n">edge_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_featurizer</span><span class="p">(</span><span class="n">continuous_edge_features</span><span class="p">,</span> <span class="n">categorical_edge_features</span><span class="p">)</span>
    <span class="n">edge_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;edge_mask&#39;</span><span class="p">]</span>
    <span class="n">masked_edge_features</span> <span class="o">=</span> <span class="n">edge_features</span> <span class="o">*</span> <span class="n">edge_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># We have now embedded the node features, we&#39;ll propagate them through our </span>
    <span class="c1"># graph layers</span>
    <span class="n">adjacency_matrix</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;adjacency_matrices&#39;</span><span class="p">]</span>
    <span class="n">memory_state</span> <span class="o">=</span> <span class="n">masked_node_features</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_layers</span><span class="p">:</span>
      <span class="n">memory_state</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">memory_state</span><span class="p">,</span> <span class="n">masked_edge_features</span> <span class="p">,</span> <span class="n">node_mask</span><span class="p">,</span> <span class="n">edge_mask</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">memory_state</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GraphPredictionNeuralNetwork</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">prediction_head</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prediction_head</span> <span class="o">=</span> <span class="n">prediction_head</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">encoded_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction_head</span><span class="p">(</span><span class="n">encoded_graph</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;nodes_mask&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">prediction</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">basic_encoder_config</span> <span class="o">=</span> <span class="n">BasicTransformerConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> 
                                      <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                      <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                      <span class="n">head_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                      <span class="n">layer_normalization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                      <span class="n">residual_connections</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">basic_transformer</span> <span class="o">=</span> <span class="n">BasicTransformerEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">basic_encoder_config</span><span class="p">,</span> 
                                            <span class="n">continuous_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">,</span>
                                            <span class="n">categorical_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">,</span>
                                            <span class="n">continuous_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">,</span>
                                            <span class="n">categorical_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">)</span>

<span class="n">head_config</span> <span class="o">=</span> <span class="n">GraphPredictionHeadConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">prediction_head</span> <span class="o">=</span> <span class="n">GraphPredictionHead</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">head_config</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GraphPredictionNeuralNetwork</span><span class="p">(</span><span class="n">basic_transformer</span><span class="p">,</span> <span class="n">prediction_head</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                  <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
                  <span class="n">training_dataloader</span><span class="o">=</span><span class="n">training_dataloader</span><span class="p">,</span>
                  <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "774c06c7bd964097bfcd5da0d8f92ad7", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "a7fb300bbdc54b11979ae3426b5f9339", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "8b2917d1b3834705b3953fcf6f350181", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
</section>
<section id="adding-the-graph-structure-to-transformers">
<h2>Adding the graph structure to Transformers<a class="headerlink" href="#adding-the-graph-structure-to-transformers" title="Permalink to this heading"></a></h2>
<p>In basic GNNs, we take the graph strucuture into account by using the <em>given</em> adjacency matrix. In the Transformer we’ve seen now, we <em>compute</em> an <em>attention matrix</em>, a matrix which plays the same role as the adjacency matrix of the basic graph neural network.</p>
<p>We can simply modify our <em>attention function</em> of the Transformer to also take the adjacency matrix into account.</p>
<p>This attention function could really be anything, but for now we’ll stick with a very simple idea of modifying the logits of our scaled dot-product attention by adding a scalar to the logits if there is a 1 in the adjacency matrix for that place.</p>
<p>If $a_{i,j}$ is the the value before the softmax of the <em>attention logit</em> matrix for how much we should include information from node $j$ when aggregating for node $i$, we define a function:</p>
<p>$$
a_{i,j} = f(\mathbf{x_i}, \mathbf{x_j}) =
\frac{&lt;\mathbf{x_i}, \mathbf{x_j}&gt;}{\sqrt{\text{d_model}}} + w\mathbf{1}_{{i, j} \in E}
$$</p>
<p>Here ${1}_{{i, j} \in E}$ is the indicator function taking the value $1$ if there is an edge between  $i$ and $j$ (in other words, the $i,j$ entry of the adjacency matrix).</p>
<p>We also add a learnable scalar $w$ which the network can learn to set to change what influence the prescence of an edge has on the attention score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="k">class</span> <span class="nc">AdjacencyTransformerLayer</span><span class="p">(</span><span class="n">BasicTransformerLayer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">attention_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">center_node_features</span><span class="p">,</span> 
                         <span class="n">neighbour_node_features</span><span class="p">,</span> <span class="n">edge_features</span><span class="p">,</span> <span class="n">node_mask</span><span class="p">,</span> <span class="n">edge_mask</span><span class="p">):</span>
    <span class="c1"># We still take the </span>
    <span class="n">dot_product_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">center_node_features</span><span class="p">,</span> 
                                                <span class="n">neighbour_node_features</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span>

    <span class="c1"># The adjacency_matrix is scaled by a parameter so that the network can</span>
    <span class="c1"># learn to adjust the influence of edge presence</span>
    <span class="n">adjacency_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adjacency_weight</span><span class="o">*</span><span class="n">adjacency_matrix</span>
    <span class="n">attention_logits</span> <span class="o">=</span> <span class="n">dot_product_logits</span> <span class="o">+</span> <span class="n">adjacency_logits</span>

    <span class="n">nodemask_2d</span> <span class="o">=</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fill_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nodemask_2d</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="n">attention_logits</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">fill_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">))</span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">attention_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># There will be rows of the smaller attention matrices which where filled</span>
    <span class="c1"># completely with -inf values, these will now be rows of &#39;nan&#39; values</span>
    <span class="c1"># We perform a new fill of the attention matrix, but this time with 0s </span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">attention_matrix</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">fill_mask</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attention_matrix</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">basic_encoder_config</span> <span class="o">=</span> <span class="n">BasicTransformerConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> 
                                      <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                      <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                      <span class="n">head_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                      <span class="n">layer_normalization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                      <span class="n">residual_connections</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">basic_transformer</span> <span class="o">=</span> <span class="n">BasicTransformerEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">basic_encoder_config</span><span class="p">,</span> 
                                            <span class="n">continuous_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">,</span>
                                            <span class="n">categorical_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">,</span>
                                            <span class="n">continuous_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">,</span>
                                            <span class="n">categorical_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">,</span>
                                            <span class="n">layer_type</span><span class="o">=</span><span class="n">AdjacencyTransformerLayer</span><span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">GraphPredictionHeadConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">prediction_head</span> <span class="o">=</span> <span class="n">GraphPredictionHead</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">head_config</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">head_config</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GraphPredictionNeuralNetwork</span><span class="p">(</span><span class="n">basic_transformer</span><span class="p">,</span> <span class="n">prediction_head</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                  <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
                  <span class="n">training_dataloader</span><span class="o">=</span><span class="n">training_dataloader</span><span class="p">,</span>
                  <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "62b8e93c07c2466d9a48127c951b9bcb", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "3f12595a485641ae92f0dd25606d7c55", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "864697da89b942988cface87062cb27b", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="edge-features-in-the-attention">
<h2>Edge features in the attention<a class="headerlink" href="#edge-features-in-the-attention" title="Permalink to this heading"></a></h2>
<p>In the previous example, we only used the <em>adjacency matrix</em> to influence the attention function. Now we’ll extend this to actually include edge features as well.</p>
<p>To do this we simply extend this notion of using a function to compute the values of the attention matrix, in particular we will use function which takes the feature nodes for the center and neighbour node as well as the edge feature vector between these nodes. For nodes which have no feature vector, the zero-vector will be used.</p>
<p>This function will be implemented by a simple 2 layer MLP. And we choose to implement it as below</p>
<p>$$
a_{i,j} = f(\mathbf{x_i}, \mathbf{x_j}, \mathbf{x_{e_{i,j}}}) =
W_2 \sigma(W_1 (\mathbf{x_i} + \mathbf{x_j} + \mathbf{x_{e_{i,j}}}) + \mathbf{b_1}) + \mathbf{b_2}
$$</p>
<p>You can see that we apply the neural network on the sum the vectors of node features and edge features. This will make this function permutation invariant of its inputs (i.e. $f(\mathbf{x_i}, \mathbf{x_j}, \mathbf{x_{e_{i,j}}}) = f( \mathbf{x_j}, \mathbf{x_{e_{i,j}}}, \mathbf{x_i},)$. If this is not desired, concatenation can be used instead but makes the implementation a bit more complex.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EdgeAttributesAttentionTransformerLayer</span><span class="p">(</span><span class="n">BasicTransformerLayer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># We&#39;re going to sum our center and neighbour vectors to the edge feature</span>
    <span class="c1"># vector, so have to be mindful of the dimensionality</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">center_transform</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">neighbour_transform</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attention_score_function</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> 
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">),</span> 
                                               <span class="n">ReLU</span><span class="p">(),</span> 
                                               <span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">,</span> 
                                                      <span class="mi">1</span><span class="p">))</span>

    
  <span class="k">def</span> <span class="nf">attention_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">center_node_features</span><span class="p">,</span> 
                         <span class="n">neighbour_node_features</span><span class="p">,</span> <span class="n">edge_features</span><span class="p">,</span> 
                         <span class="n">node_mask</span><span class="p">,</span> <span class="n">edge_mask</span><span class="p">):</span>
    <span class="c1"># Our goal is to first build up the input tensor to our simple MLP. </span>
    <span class="c1"># This will be a tensor of shape </span>
    <span class="c1"># (*leading_dimension, n_nodes, n_nodes, feature_dim)</span>
    <span class="c1"># The edge_feature&#39;s tensor already has this shape, and we&#39;ve made sure</span>
    <span class="c1"># the edge features on that tensor is already zeroed for places where</span>
    <span class="c1"># there are no edges.</span>
    <span class="c1"># We want each element [...,i,j,:] of this matrix to be </span>
    <span class="c1"># center_node_features[i] + neighbour_node_features[j] + edge_features[i,j]</span>
    <span class="c1"># We achieve this by broadcasting once again, the center node features</span>
    <span class="c1"># are broadcasted along the -3&#39;rd axis and the neighbour node features</span>
    <span class="c1"># along the -2&#39;nd axis which gives us the desired result</span>
    <span class="c1"># This is one of the most annyoing things with the frameworks we use, </span>
    <span class="c1"># having to be very conscious about the order of axises</span>
    <span class="c1"># unsqueeze(-2) broadcasts along the &quot;row&quot; of this batch of edge feature &quot;matrices&quot;</span>
    <span class="n">attention_score_input</span> <span class="o">=</span> <span class="n">edge_features</span> <span class="o">+</span> <span class="n">center_node_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> 
    <span class="c1"># unsqueeze(-3) broadcasts along the &quot;columns&quot; if the 3-tensor</span>
    <span class="n">attention_score_input</span> <span class="o">=</span> <span class="n">attention_score_input</span> <span class="o">+</span> <span class="n">neighbour_node_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
    
    <span class="n">attention_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_score_function</span><span class="p">(</span><span class="n">attention_score_input</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    
    <span class="c1"># We need to perform the same masking as before</span>
    <span class="n">nodemask_2d</span> <span class="o">=</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fill_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nodemask_2d</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    
    <span class="n">attention_logits</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">fill_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">))</span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">attention_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">attention_matrix</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">fill_mask</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attention_matrix</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">basic_encoder_config</span> <span class="o">=</span> <span class="n">BasicTransformerConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> 
                                      <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                      <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                      <span class="n">head_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                      <span class="n">layer_normalization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                      <span class="n">residual_connections</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">basic_transformer</span> <span class="o">=</span> <span class="n">BasicTransformerEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">basic_encoder_config</span><span class="p">,</span> 
                                            <span class="n">continuous_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">,</span>
                                            <span class="n">categorical_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">,</span>
                                            <span class="n">continuous_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">,</span>
                                            <span class="n">categorical_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">,</span>
                                            <span class="n">layer_type</span><span class="o">=</span><span class="n">EdgeAttributesAttentionTransformerLayer</span><span class="p">)</span>

<span class="n">head_config</span> <span class="o">=</span> <span class="n">GraphPredictionHeadConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">prediction_head</span> <span class="o">=</span> <span class="n">GraphPredictionHead</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">head_config</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GraphPredictionNeuralNetwork</span><span class="p">(</span><span class="n">basic_transformer</span><span class="p">,</span> <span class="n">prediction_head</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                  <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
                  <span class="n">training_dataloader</span><span class="o">=</span><span class="n">training_dataloader</span><span class="p">,</span>
                  <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "d5b7af95c5ca4d6fb9c839aad3a773eb", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "e933598f725846619d68532a266bf1c6", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "c53529ac23834684b2d8d5b7ce839208", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="edge-features-in-the-transformations">
<h2>Edge features in the transformations<a class="headerlink" href="#edge-features-in-the-transformations" title="Permalink to this heading"></a></h2>
<p>While the basic Transformer can include pairwise information (such as the adjacency matrix) in its attention function, this is only used to decide what node vectors to aggregate, i.e. the values of the attention matrix (our dynamic adjacency matrix).</p>
<p>In the GNN we looked at in the last notebook, edge feature vectors where integrated into the <em>message</em> “passed” from the neighbour nodes, and could be used by the MLP parts of the network to learn a combined representation of the node features and edge features and eventually directly part of the output.</p>
<p>We can extend the Transformer architecture to also do this just like we did in the example on GNNs. We will still use the underlying idea of <em>computing</em> an adjacency matrix to have a dynamic aggregation function, but instead making the aggregated neighbourhood be contexually different based on what node we’re currently aggregating for.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="k">class</span> <span class="nc">EdgeAttributesTransformerLayer</span><span class="p">(</span><span class="n">EdgeAttributesAttentionTransformerLayer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">node_features</span><span class="p">,</span> <span class="n">edge_features</span><span class="p">,</span> <span class="n">node_mask</span><span class="p">,</span> <span class="n">edge_mask</span><span class="p">):</span>
    <span class="n">center_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_transform</span><span class="p">(</span><span class="n">node_features</span><span class="p">)</span>
    <span class="n">neighbour_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_transform</span><span class="p">(</span><span class="n">node_features</span><span class="p">)</span>
    <span class="n">attention_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_function</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> 
                                               <span class="n">center_node_features</span><span class="p">,</span>
                                               <span class="n">neighbour_node_features</span><span class="p">,</span> 
                                               <span class="n">edge_features</span><span class="p">,</span> 
                                               <span class="n">node_mask</span><span class="p">,</span> 
                                               <span class="n">edge_mask</span><span class="p">)</span>
    <span class="c1"># Just like when we computed the attention scores using the edge feature </span>
    <span class="c1"># vectors we also want to create context-dependent neighbourhoods now</span>
    <span class="c1"># We do that by creating the full pairwise tensor of shape</span>
    <span class="c1"># (*leading_dimensions, n_nodes, n_nodes, num_features). We use the same</span>
    <span class="c1"># procedure with broadcasting in the </span>
    <span class="c1"># EdgeAttributesAttentionTransformerLayer attention_function above</span>
    <span class="c1"># unsqueeze(-2) broadcasts along the &quot;row&quot; of this batch of edge feature &quot;matrices&quot;</span>
    <span class="n">context_dependent_features</span> <span class="o">=</span> <span class="n">edge_features</span> <span class="o">+</span> <span class="n">center_node_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> 
    <span class="c1"># unsqueeze(-3) broadcasts along the &quot;columns&quot; if the 3-tensor</span>
    <span class="n">context_dependent_features</span> <span class="o">=</span> <span class="n">context_dependent_features</span> <span class="o">+</span> <span class="n">neighbour_node_features</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
    
    <span class="c1"># Now the aggregation becomes a bit more tricky. We did this in the GNN layer</span>
    <span class="c1"># which used edge features as well, essentially explicitly performing what </span>
    <span class="c1"># used a matrix multiplaction to do previously: broadcast the attention matrix</span>
    <span class="c1"># over the feature dimension: multiplying a feature vector at position i,j </span>
    <span class="c1"># with the value in the attention matrix at position i,j</span>
    <span class="n">attended_features</span> <span class="o">=</span> <span class="n">context_dependent_features</span> <span class="o">*</span> <span class="n">attention_matrix</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Now the aggregation is performed by summing these attended features along </span>
    <span class="c1"># the &quot;rows&quot;, i.e. reducing away the &quot;column&quot; axis which is dim=-2</span>
    <span class="n">aggregated_neighbourhoods</span> <span class="o">=</span> <span class="n">attended_features</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>  

    <span class="c1"># Now maske the result as before</span>
    <span class="n">masked_features</span> <span class="o">=</span> <span class="n">aggregated_neighbourhoods</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Followed by a dropout, layer normalization and residual sum</span>
    <span class="n">masked_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">masked_features</span><span class="p">)</span>
    <span class="n">masked_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_norm</span><span class="p">(</span><span class="n">masked_features</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
      <span class="n">masked_features</span> <span class="o">=</span> <span class="n">masked_features</span> <span class="o">+</span> <span class="n">node_features</span>

    <span class="c1"># Transform the features with our MLP</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span><span class="p">(</span><span class="n">masked_features</span><span class="p">)</span>

    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="n">updated_node_features</span> <span class="o">*</span> <span class="n">node_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Followed by a dropout and normalization</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">updated_node_features</span><span class="p">)</span>
    <span class="n">updated_node_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">updated_node_features</span><span class="p">)</span>

    <span class="c1"># And the resiudal connection from the input to the output MLP</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
      <span class="n">updated_node_features</span> <span class="o">=</span> <span class="n">updated_node_features</span> <span class="o">+</span> <span class="n">masked_features</span>

    <span class="k">return</span> <span class="n">updated_node_features</span>

  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">basic_encoder_config</span> <span class="o">=</span> <span class="n">BasicTransformerConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> 
                                      <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                      <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                      <span class="n">head_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                      <span class="n">layer_normalization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                      <span class="n">residual_connections</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">basic_transformer</span> <span class="o">=</span> <span class="n">BasicTransformerEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">basic_encoder_config</span><span class="p">,</span> 
                                            <span class="n">continuous_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">,</span>
                                            <span class="n">categorical_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">,</span>
                                            <span class="n">continuous_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">,</span>
                                            <span class="n">categorical_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">,</span>
                                            <span class="n">layer_type</span><span class="o">=</span><span class="n">EdgeAttributesTransformerLayer</span><span class="p">)</span>

<span class="n">head_config</span> <span class="o">=</span> <span class="n">GraphPredictionHeadConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">prediction_head</span> <span class="o">=</span> <span class="n">GraphPredictionHead</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">head_config</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GraphPredictionNeuralNetwork</span><span class="p">(</span><span class="n">basic_transformer</span><span class="p">,</span> <span class="n">prediction_head</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                  <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
                  <span class="n">training_dataloader</span><span class="o">=</span><span class="n">training_dataloader</span><span class="p">,</span>
                  <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "3462cf2081354ce5b87ad6c188a73107", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "a56e8722bc054ec8a8a3f86623f4d893", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "6c7cabdf6e4543ddb2e4606b0d6374a7", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="pairwise-features">
<h2>Pairwise features<a class="headerlink" href="#pairwise-features" title="Permalink to this heading"></a></h2>
<p>In the Graph Neural Network framework, we tend to focus on node attributes and edge attributes. With the Transformer framework we have instead an architecture which is based on all pairwise interaction between nodes. This allows us to extend the idea of what <em>edge features</em> could be.</p>
<p>Instead of only specifying features for pairs of nodes which have an edge, we can think of features between any pair of nodes.
This can be used to give the network information about node relationships which it struggles to learn, but can easily compute with regular algorithms, such as distance between nodes if they are embedded in an euclidean space, or the shortest path between them if they are in a graph.</p>
<p>This latter idea is the idea of a <em>path-augmented graph transformer</em> <a class="reference external" href="https://arxiv.org/abs/1905.12712">Chen Benson et al. “Path-augmented graph transformer network.”</a>.</p>
<p>We can use the architecture we’ve already defined above but allow our <em>edge features</em> to actually be <em>pairwise features</em>. Instead of only having features for pairs of nodes which are directly connected to the graph, we introduce features between any pair of nodes.</p>
<p>In this case the pairwise features will contain information about the edges along the shortest path of our graph, to at most <code class="docutils literal notranslate"><span class="pre">max_path_length</span></code> steps (longer paths are just truncated).</p>
<section id="representing-the-path-information">
<h3>Representing the path information<a class="headerlink" href="#representing-the-path-information" title="Permalink to this heading"></a></h3>
<p>In the graph, the shortest path is defined by the edges between two nodes. A natural way of representing the path is then a sequence of the edge features along this shortest path.</p>
<p>To handle the sequence information of these edges we could aggregate the path information using a sequence model such as a Recurrent Neural Network or a Transformer. In this example we make things a bit simpler and just represent the path features as separate categorical variables.
We’ll add these variables between all pairs of nodes.</p>
<p>Since we have to decide on exactly what categorical variables to use when defining the network architecture, we decide on some max length $k$ and only take edge features along the path up to that number.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_path_length</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># This is the k we limit our path lengths to</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem.rdmolops</span> <span class="kn">import</span> <span class="n">GetShortestPath</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>


<span class="n">PAIRWISE_FEATURES</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">BOND_FEATURES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;type_feature&#39;</span><span class="p">:</span> <span class="n">TYPE_FEATURE</span><span class="p">,</span> 
                 <span class="s1">&#39;direction_feature&#39;</span><span class="p">:</span> <span class="n">DIRECTION_FEATURE</span><span class="p">,</span> 
                 <span class="s1">&#39;aromatic_feature&#39;</span><span class="p">:</span> <span class="n">AROMATIC_FEATURE</span><span class="p">,</span> 
                 <span class="s1">&#39;stereo_feature&#39;</span><span class="p">:</span> <span class="n">STEREO_FEATURE</span><span class="p">}</span>

<span class="n">PAIRWISE_FEATURES</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">BOND_FEATURES</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="c1"># We careate a copy of the bond features for each path step</span>
<span class="n">PATH_FEATURES</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_path_length</span><span class="p">):</span>
  <span class="n">path_vars</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">feature_kw</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">BOND_FEATURES</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span>
    <span class="n">path_var_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_p</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">ContinuousVariable</span><span class="p">):</span>
      <span class="n">path_var</span> <span class="o">=</span> <span class="n">ContinuousVariable</span><span class="p">(</span><span class="n">path_var_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">CategoricalVariable</span><span class="p">):</span>
      <span class="n">path_var_values</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">values</span>
      <span class="n">path_var</span> <span class="o">=</span> <span class="n">CategoricalVariable</span><span class="p">(</span><span class="n">path_var_name</span><span class="p">,</span> <span class="n">path_var_values</span><span class="p">,</span> <span class="n">add_null_value</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">path_vars</span><span class="p">[</span><span class="n">feature_kw</span><span class="p">]</span> <span class="o">=</span> <span class="n">path_var</span>
    <span class="n">PAIRWISE_FEATURES</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path_var</span><span class="p">)</span>
  <span class="n">PATH_FEATURES</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path_vars</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_shortest_paths_bond_features</span><span class="p">(</span><span class="n">rd_bond</span><span class="p">,</span>
                      <span class="o">*</span><span class="p">,</span>
                      <span class="n">type_feature</span><span class="p">,</span>
                      <span class="n">direction_feature</span><span class="p">,</span>
                      <span class="n">aromatic_feature</span><span class="p">,</span>
                      <span class="n">stereo_feature</span><span class="p">):</span>
  
  <span class="k">if</span> <span class="n">rd_bond</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">bond_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetBondType</span><span class="p">())</span>
    <span class="n">bond_stereo_info</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetStereo</span><span class="p">())</span>
    <span class="n">bond_direction</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">rd_bond</span><span class="o">.</span><span class="n">GetBondDir</span><span class="p">())</span>
    <span class="n">is_aromatic</span> <span class="o">=</span> <span class="n">rd_bond</span><span class="o">.</span><span class="n">GetIsAromatic</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">bond_type</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">bond_stereo_info</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">bond_direction</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">is_aromatic</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">return</span> <span class="p">{</span><span class="n">type_feature</span><span class="p">:</span> <span class="n">bond_type</span><span class="p">,</span>
          <span class="n">direction_feature</span><span class="p">:</span> <span class="n">bond_direction</span><span class="p">,</span>
          <span class="n">aromatic_feature</span><span class="p">:</span> <span class="n">is_aromatic</span><span class="p">,</span>
          <span class="n">stereo_feature</span><span class="p">:</span> <span class="n">bond_stereo_info</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">get_pairwise_features</span><span class="p">(</span><span class="n">rd_mol</span><span class="p">,</span> <span class="n">rd_atom_a</span><span class="p">,</span> <span class="n">rd_atom_b</span><span class="p">):</span>
  <span class="n">pairwise_features</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="c1"># First we create the features for the bond (or missing such) between</span>
  <span class="c1"># the two atoms</span>
  <span class="n">bond</span> <span class="o">=</span> <span class="n">rd_mol</span><span class="o">.</span><span class="n">GetBondBetweenAtoms</span><span class="p">(</span><span class="n">rd_atom_a</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">(),</span> <span class="n">rd_atom_b</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">())</span>
  <span class="n">bond_features</span> <span class="o">=</span> <span class="n">get_shortest_paths_bond_features</span><span class="p">(</span><span class="n">bond</span><span class="p">,</span> <span class="o">**</span><span class="n">BOND_FEATURES</span><span class="p">)</span>
  
  <span class="n">pairwise_features</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">bond_features</span><span class="p">)</span>
  <span class="c1"># Now we create bond features for the path between rd_atom_a and rd_atom_b</span>
  <span class="c1"># We iterate over atoms of the shortest path up till max_path_length</span>
  <span class="c1"># If the shortest path is shorter than max_path_length, we add None-valued</span>
  <span class="c1"># features for the remaining ones</span>
  <span class="n">shortest_path</span> <span class="o">=</span> <span class="n">GetShortestPath</span><span class="p">(</span><span class="n">rd_mol</span><span class="p">,</span> <span class="n">rd_atom_a</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">(),</span> <span class="n">rd_atom_b</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">())</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_path_length</span><span class="p">):</span>
    <span class="n">path_bond_variables</span> <span class="o">=</span> <span class="n">PATH_FEATURES</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shortest_path</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">shortest_path</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shortest_path</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">path_bond</span> <span class="o">=</span> <span class="n">rd_mol</span><span class="o">.</span><span class="n">GetBondBetweenAtoms</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">path_bond</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">path_bond_features</span> <span class="o">=</span> <span class="n">get_shortest_paths_bond_features</span><span class="p">(</span><span class="n">path_bond</span><span class="p">,</span> <span class="o">**</span><span class="n">path_bond_variables</span><span class="p">)</span>
    <span class="n">pairwise_features</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">path_bond_features</span><span class="p">)</span>

  
  <span class="k">return</span> <span class="n">pairwise_features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rd_mol</span> <span class="o">=</span> <span class="n">MolFromSmiles</span><span class="p">(</span><span class="s1">&#39;CCCCCC&#39;</span><span class="p">)</span>
<span class="n">atom_a</span> <span class="o">=</span> <span class="n">rd_mol</span><span class="o">.</span><span class="n">GetAtomWithIdx</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">atom_b</span> <span class="o">=</span> <span class="n">rd_mol</span><span class="o">.</span><span class="n">GetAtomWithIdx</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">get_pairwise_features</span><span class="p">(</span><span class="n">rd_mol</span><span class="p">,</span> <span class="n">atom_a</span><span class="p">,</span> <span class="n">atom_b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&lt;CategoricalVariable: bond_direction&gt;: &#39;NONE&#39;,
 &lt;CategoricalVariable: bond_direction_p0&gt;: &#39;NONE&#39;,
 &lt;CategoricalVariable: bond_direction_p1&gt;: None,
 &lt;CategoricalVariable: bond_direction_p2&gt;: None,
 &lt;CategoricalVariable: bond_stereo&gt;: &#39;STEREONONE&#39;,
 &lt;CategoricalVariable: bond_stereo_p0&gt;: &#39;STEREONONE&#39;,
 &lt;CategoricalVariable: bond_stereo_p1&gt;: None,
 &lt;CategoricalVariable: bond_stereo_p2&gt;: None,
 &lt;CategoricalVariable: bond_type&gt;: &#39;SINGLE&#39;,
 &lt;CategoricalVariable: bond_type_p0&gt;: &#39;SINGLE&#39;,
 &lt;CategoricalVariable: bond_type_p1&gt;: None,
 &lt;CategoricalVariable: bond_type_p2&gt;: None,
 &lt;CategoricalVariable: is_aromatic&gt;: False,
 &lt;CategoricalVariable: is_aromatic_p0&gt;: False,
 &lt;CategoricalVariable: is_aromatic_p1&gt;: None,
 &lt;CategoricalVariable: is_aromatic_p2&gt;: None}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">atom_a</span> <span class="o">=</span> <span class="n">rd_mol</span><span class="o">.</span><span class="n">GetAtomWithIdx</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">atom_b</span> <span class="o">=</span> <span class="n">rd_mol</span><span class="o">.</span><span class="n">GetAtomWithIdx</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">get_pairwise_features</span><span class="p">(</span><span class="n">rd_mol</span><span class="p">,</span> <span class="n">atom_a</span><span class="p">,</span> <span class="n">atom_b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&lt;CategoricalVariable: bond_direction&gt;: None,
 &lt;CategoricalVariable: bond_direction_p0&gt;: &#39;NONE&#39;,
 &lt;CategoricalVariable: bond_direction_p1&gt;: &#39;NONE&#39;,
 &lt;CategoricalVariable: bond_direction_p2&gt;: &#39;NONE&#39;,
 &lt;CategoricalVariable: bond_stereo&gt;: None,
 &lt;CategoricalVariable: bond_stereo_p0&gt;: &#39;STEREONONE&#39;,
 &lt;CategoricalVariable: bond_stereo_p1&gt;: &#39;STEREONONE&#39;,
 &lt;CategoricalVariable: bond_stereo_p2&gt;: &#39;STEREONONE&#39;,
 &lt;CategoricalVariable: bond_type&gt;: None,
 &lt;CategoricalVariable: bond_type_p0&gt;: &#39;SINGLE&#39;,
 &lt;CategoricalVariable: bond_type_p1&gt;: &#39;SINGLE&#39;,
 &lt;CategoricalVariable: bond_type_p2&gt;: &#39;SINGLE&#39;,
 &lt;CategoricalVariable: is_aromatic&gt;: None,
 &lt;CategoricalVariable: is_aromatic_p0&gt;: False,
 &lt;CategoricalVariable: is_aromatic_p1&gt;: False,
 &lt;CategoricalVariable: is_aromatic_p2&gt;: False}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rdmol_to_complete_graph</span><span class="p">(</span><span class="n">mol</span><span class="p">):</span>
  <span class="n">atoms</span> <span class="o">=</span> <span class="p">{</span><span class="n">rd_atom</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">():</span> <span class="n">get_atom_features</span><span class="p">(</span><span class="n">rd_atom</span><span class="p">)</span> <span class="k">for</span> <span class="n">rd_atom</span> <span class="ow">in</span> <span class="n">mol</span><span class="o">.</span><span class="n">GetAtoms</span><span class="p">()}</span>
  <span class="n">all_pairwise_features</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">atom_a</span><span class="p">,</span> <span class="n">atom_b</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">mol</span><span class="o">.</span><span class="n">GetAtoms</span><span class="p">(),</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">all_pairwise_features</span><span class="p">[</span><span class="nb">frozenset</span><span class="p">((</span><span class="n">atom_a</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">(),</span> <span class="n">atom_b</span><span class="o">.</span><span class="n">GetIdx</span><span class="p">()))]</span> <span class="o">=</span> <span class="n">get_pairwise_features</span><span class="p">(</span><span class="n">mol</span><span class="p">,</span> <span class="n">atom_a</span><span class="p">,</span> <span class="n">atom_b</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">atoms</span><span class="p">,</span> <span class="n">all_pairwise_features</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">smiles_to_complete_graph</span><span class="p">(</span><span class="n">smiles</span><span class="p">):</span>
  <span class="n">rd_mol</span> <span class="o">=</span> <span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">rdmol_to_complete_graph</span><span class="p">(</span><span class="n">rd_mol</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">graph</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">process_smiles_record</span><span class="p">(</span><span class="n">smiles_record</span><span class="p">):</span>
  <span class="n">smiles</span> <span class="o">=</span> <span class="n">smiles_record</span><span class="p">[</span><span class="s1">&#39;smiles&#39;</span><span class="p">]</span>
  <span class="n">rdmol</span> <span class="o">=</span> <span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
  <span class="n">label</span> <span class="o">=</span> <span class="n">smiles_record</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">rdmol_to_complete_graph</span><span class="p">(</span><span class="n">rdmol</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">graph</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">smiles_record</span>

<span class="k">def</span> <span class="nf">make_graph_shortest_path_dataset</span><span class="p">(</span><span class="n">smiles_records</span><span class="p">,</span> 
                                              <span class="n">atom_features</span><span class="o">=</span><span class="n">ATOM_FEATURES</span><span class="p">,</span> 
                                              <span class="n">bond_features</span><span class="o">=</span><span class="n">PAIRWISE_FEATURES</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  Create a new GraphDataset from a list of smiles_records dictionaries.</span>
<span class="sd">  These records should contain the key &#39;smiles&#39; and &#39;label&#39;. Any other keys will be saved as a &#39;metadata&#39; record.</span>
<span class="sd">  The &#39;label&#39; record will be ignored, and instead be replaced by the diameter of the graph.</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">graphs</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">with</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">()</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">graph</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">smiles_record</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">pool</span><span class="o">.</span><span class="n">imap</span><span class="p">(</span><span class="n">process_smiles_record</span><span class="p">,</span> <span class="n">smiles_records</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">smiles_records</span><span class="p">)):</span>
      <span class="n">graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
      <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
      <span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smiles_record</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">GraphDataset</span><span class="p">(</span><span class="n">graphs</span><span class="o">=</span><span class="n">graphs</span><span class="p">,</span> 
                      <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> 
                      <span class="n">node_variables</span><span class="o">=</span><span class="n">atom_features</span><span class="p">,</span> 
                      <span class="n">edge_variables</span><span class="o">=</span><span class="n">bond_features</span><span class="p">,</span> 
                      <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">)</span>
  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">make_graph_shortest_path_dataset</span><span class="p">([{</span><span class="s1">&#39;smiles&#39;</span><span class="p">:</span> <span class="s1">&#39;c1ccccc1&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">},{</span><span class="s1">&#39;smiles&#39;</span><span class="p">:</span><span class="s1">&#39;OS(=O)(=O)O&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "725536c155514d248be3564b7ed27023", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_shortest_path_dataset</span> <span class="o">=</span> <span class="n">make_graph_shortest_path_dataset</span><span class="p">(</span><span class="n">training_smiles_records</span><span class="p">)</span>
<span class="n">dev_shortest_path_dataset</span> <span class="o">=</span> <span class="n">make_graph_shortest_path_dataset</span><span class="p">(</span><span class="n">dev_smiles_records</span><span class="p">)</span>
<span class="n">test_shortest_path_dataset</span> <span class="o">=</span> <span class="n">make_graph_shortest_path_dataset</span><span class="p">(</span><span class="n">test_smiles_records</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "40707fb8b6c5483daa77dbe8388ea77d", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "78b08f8a809941e0a91ecd612a2ad1c7", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "eec1acab2f8e46e3bdb0fb9a1df7b2f2", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">num_dataloader_workers</span><span class="o">=</span><span class="mi">2</span> <span class="c1"># The colab instances are very limited in number of cpus</span>

<span class="n">training_shortest_path_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">training_shortest_path_dataset</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                          <span class="n">num_workers</span><span class="o">=</span><span class="n">num_dataloader_workers</span><span class="p">,</span> 
                                          <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_graph_batch</span><span class="p">)</span>
<span class="n">dev_shortest_path_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dev_shortest_path_dataset</span><span class="p">,</span> 
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">num_workers</span><span class="o">=</span><span class="n">num_dataloader_workers</span><span class="p">,</span> 
                                     <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_graph_batch</span><span class="p">)</span>
<span class="n">test_shortest_path_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_shortest_path_dataset</span><span class="p">,</span> 
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">num_workers</span><span class="o">=</span><span class="n">num_dataloader_workers</span><span class="p">,</span> 
                                     <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                     <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_graph_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">basic_encoder_config</span> <span class="o">=</span> <span class="n">BasicTransformerConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> 
                                      <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                      <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                      <span class="n">head_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                      <span class="n">layer_normalization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                      <span class="n">residual_connections</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">basic_transformer</span> <span class="o">=</span> <span class="n">BasicTransformerEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">basic_encoder_config</span><span class="p">,</span> 
                                            <span class="n">continuous_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_node_variables</span><span class="p">,</span>
                                            <span class="n">categorical_node_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_node_variables</span><span class="p">,</span>
                                            <span class="n">continuous_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">continuous_edge_variables</span><span class="p">,</span>
                                            <span class="n">categorical_edge_variables</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">categorical_edge_variables</span><span class="p">,</span>
                                            <span class="n">layer_type</span><span class="o">=</span><span class="n">EdgeAttributesTransformerLayer</span><span class="p">)</span>

<span class="n">head_config</span> <span class="o">=</span> <span class="n">GraphPredictionHeadConfig</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">prediction_head</span> <span class="o">=</span> <span class="n">GraphPredictionHead</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">head_config</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GraphPredictionNeuralNetwork</span><span class="p">(</span><span class="n">basic_transformer</span><span class="p">,</span> <span class="n">prediction_head</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                  <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span> 
                  <span class="n">training_dataloader</span><span class="o">=</span><span class="n">training_shortest_path_dataloader</span><span class="p">,</span>
                  <span class="n">dev_dataloader</span><span class="o">=</span><span class="n">dev_shortest_path_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="slow-training">
<h3>Slow training<a class="headerlink" href="#slow-training" title="Permalink to this heading"></a></h3>
<p>You will notice that this model is much slower to train than the previous. That’s not because of changes to the neural network (you can see that it’s exactly the same as before) but because the input is now much more complex. Each edge now has <code class="docutils literal notranslate"><span class="pre">max_path_length</span></code> as many features as before. This makes the dataloading and embedding steps more time consuming.</p>
<p>In particular, the Colab instances we’re using only have 2 processors, so we can’t get much help from doing batch preprocessing in parallel. When training on proper hardware, this time would be hidden due to multiprocessing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c019bd6daa0e431b94132a1347fa7497", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "49ec3361e813400781d4ad5d24e737ab", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "3c0f494b88cb43d8ab0364ae197fa66a", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
</section>
<section id="a-note-on-efficiency">
<h2>A note on efficiency<a class="headerlink" href="#a-note-on-efficiency" title="Permalink to this heading"></a></h2>
<p>We’ve seen how we can effectively extend our graph neural network to not only use the neighbourhood of aggregation, and this allows us to embed a lot of domain knowledge into how we represent our problems.</p>
<p>The downside is that this method scales poorly with the size of our graphs. Both computation time and memory demand will scale quadratically with the size of the input.</p>
<p>With a regular GNN, we can make the neighbourhood aggregation <em>sparse</em>, and this is what practical GNN frameworks such as PyTorch Geometric do.</p>
<p>In the field of NLP, much research is dedicated to making the transformer architecture more efficient and we will likely see developments on how this method can be more efficient in the future.</p>
</section>
<section id="task">
<h2>Task<a class="headerlink" href="#task" title="Permalink to this heading"></a></h2>
<p>Experiment with this Path-augmented Transformer. Can you do better than the GNN from the previous notebook?</p>
</section>
<section id="learning-outcomes">
<h2>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this heading"></a></h2>
<p>In this notebook we took a deep dive into Transformers. As you can see, we’ve essentially extended the idea of a graph neural network by <em>computing</em> an “adjacency matrix” (the attention matrix). The choice of what function to use to compute each element of this matrix is up to us, but for graphs it’s reasonable to use any edge information between the pair of nodes.</p>
<p>We saw how we could also include <em>any</em> pairwise information, and while we used the shortes path between the nodes in this case, for graphs embedded in a euclidean space it could have been the euclidean distance or any other information we might compute from a pair of node features.</p>
</section>
<section id="important-concepts">
<h2>Important concepts<a class="headerlink" href="#important-concepts" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Attention</p></li>
<li><p>Function on pair of nodes</p></li>
<li><p>Shortest path</p></li>
</ul>
</section>
<section id="what-about-this-multi-head-attention">
<h2>What about this <em>multi-head</em> attention?<a class="headerlink" href="#what-about-this-multi-head-attention" title="Permalink to this heading"></a></h2>
<p>When talking about Transformers, a lot of time is often given to the <em>multi-head self-attention</em>. In this notebook we haven’t covered that, mostly because the difference between multi-head and single head self-attention is conceptually small, but quite a bit more messy to implement efficiently.</p>
<section id="what-is-multi-head-self-attention">
<h3>What is multi-head self-attention?<a class="headerlink" href="#what-is-multi-head-self-attention" title="Permalink to this heading"></a></h3>
<p>In multi-head, we effectively add <em>parallel</em> networks in the aggregation part. So think of it as having multiple parallel GNN layers, each performing their own MSG and AGG step. In the end, the resulting vectors of the parallel heads are combined (concatenated in the Transformer) to form the new vector for the node.</p>
<p>This is equivalent to using <a class="reference external" href="https://en.wikipedia.org/wiki/Block_matrix#Block_diagonal_matrices">“block-diagonal”</a> weight matrices (as well as some shuffling around of results) which is an interesting way of using sparse computation for neural networks.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../session_3/3a_Graph_Neural_Network_Encoder_solutions/" class="btn btn-neutral float-left" title="Implementing a Graph Neural Network" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../../quick-reference/" class="btn btn-neutral float-right" title="Quick Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, GNN and Transformer workshop and individual contributors..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>